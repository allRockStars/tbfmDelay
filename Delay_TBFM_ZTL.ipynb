{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 â€“ Tyler Ngo<br />\n",
    "License - This work is licensed under MIT license - https://opensource.org/licenses/MIT<br />  \n",
    "PREAMBLE<br />\n",
    "This is a tutorial, written in python, to demonstrate how to solve a simple linear regression statistical problem.\n",
    "By using IPython's [rich display system](https://nbviewer.jupyter.org/github/ipython/ipython/blob/2.x/examples/Notebook/Display%20System.ipynb) capability, we also hope to turn it into a how-to document, saving us from the need to reproduce a Word Doc to serve the same purpose.<br />  \n",
    "In this example, we aim to assess TBFM-reported delays for flights heading to the meter fix ORD_DOOGE before and after APREQ prescheduling to ORD was implemented at CLT in June of 2019.<br />  \n",
    "TODO:<br />\n",
    "+ Annotate each cell to summarize what it's trying to do; make sure to explain the test statistics and the effect size<br />\n",
    "    Esp. for the effect size, I'd like to see a statement like this: \"an effect size of 0.8 means that the average delay after APREQ prescheduling is 0.8 standard deviations above the average delay before APREQ prescheduling. Alternatively, we can state that the average delay after APREQ prescheduling is higher than 79% of the delays observed before APREQ prescheduling. An effect size of .8 is categorized as large.\" This example statement clearly makes the assumption that the delay distribution is normally distributed. Review [this page](https://www.leeds.ac.uk/educol/documents/00002182.htm) to see how effect size can be interpreted.<br />\n",
    "+ Include the math formula for each test statistic (look into the math library and latex - see the link for rich display system above). We want this displayed to explain to other analysts when/how to use a test statistic.<br />\n",
    "+ Verify that the effect size is correctly computed within their function calls (I made 2: Cohen's D for normal dist. & Cliff's delta for non-parametric).<br />\n",
    "+ Ensure data are parsed correctly and that I'm picking the correct subset for each purpose<br />\n",
    "+ See if you can merge the separate plots (histograms, density, & boxplots) for each airport into one page; that would leave one quadrant for the test statistics, the effect size, and a short explanation of what they mean. Do the same for the streamclass.<br />\n",
    "+ See if you can fix some image texts, etc; goal is to make them look uniform, texts are reasonably located within the charts.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM STATEMENT<br />\n",
    "In this example, we seek to address 2 questions:<br />\n",
    "1. Is there a statistically significant difference in delay distributions before and after APREQ prescheduling was implemented in June 2019?<br />\n",
    "2. Is there a linear relationship between TBFM reported delay and the associated flight's distance to the meter fix from its departure airport?<br />  \n",
    "\n",
    "METHODS:<br />\n",
    "For the 1st question, we will assess overall delay for the ORD_DOOGE streamclass and delay for each airport going to ORD_DOOGE. We perform the following steps for each airport and overall streamclass delay before and after APREQ prescheduling:<br />\n",
    "1. Compute descriptive statistics<br />\n",
    "2. Plot delay distributions to assess location, scale, and shape<br />\n",
    "3. Assess outliers for each set of data. Here, I provided 2 methods. However, we can choose a more rigorous method to assess whether to remove or incorporate outliers if we wish.<br />\n",
    "    + Remove outliers using Z method (retains 99% of data)<br />\n",
    "    + Remove outliers using IQR method - lower cutoff=(25th percentile - 150% of IQR); upper cutoff=(75th percentile + 150% of IQR)<br />\n",
    "4. Assess the pdf of the delay distribution, then test for goodness-of-fit.  Here, I attempted 2 methods:<br />\n",
    "    + Fit a # of pdfs, select one with lowest SSE, then test for goodness of fit using dist parameters.<br />\n",
    "        - Use KS test: split data into train and test set; use train set to find dist params, use test set for goodness-of-fit.<br />\n",
    "        - You can also use Lilliefors test if you're testing against a normal or exponential dist. You don't need to split the dataset if you use Lilliefors since it also estimates the distribution parameters.<br />\n",
    "    + Use MLE starting with the dist and dist params from SSE computation to find a better dist parameters, then test for goodness-of-fit using this dist parameters. <font color='red'>This section of code needs some TLC.</font><br />\n",
    "5. Try to normalize the delay based on the knowledge we obtain from step 4. Step 4 used to be very important because in order to attempt to normalize, we have to know the pdf.  It doesn't seem to be as important now.  But step 4 is stil important in gaining insight and understanding of the data.<br />\n",
    "6. Test for normality.<br />\n",
    "    + Use KS test: split data into train and test set; use train set to find dist params, use test set for goodness-of-fit.<br />\n",
    "    + Or use Lilliefors test.<br />\n",
    "    + Just for fun, I've also added the Shapiro-Wilk test statistic to compare with the other 2. This one generally works better for larger sample sizes.<br /> \n",
    "7. Test for statistically significant difference between delay dist before and after APREQ prescheduling. Depending on whether normality test passes or not, we decide which test statistics to use.<br />\n",
    "    + If passes for normality, use Welch's-T test.<br />\n",
    "    + If test for normality does not pass, use KS test.<br />\n",
    "8. If a statistically significant difference is found, then compute effect size. Interpret the effect size to assess whether the difference was important. Here I provide 2 methods. We can investigate other methods to compute effect size.<br />\n",
    "    + Cohen's D, use if normality test is passed<br />\n",
    "    + Cliff's Delta, use for non-parametric.<br />  \n",
    "\n",
    "--------------------------------------------------------------------------<br />\n",
    "\n",
    "For the 2nd question, we will assess whether there is a linear relationship between the flight's TBFM-reported delay and its distance to the meter fix from its departure airport. We will perform the following steps:<br />\n",
    "1. Compute descriptive statistics<br />\n",
    "2. Plot delay and meterFixDistance distribution to assess location, scale, and shape<br />\n",
    "3. Assess outliers for each. See step 3 above.<br />\n",
    "4. Assess pdf for each. See step 4 above.<br />\n",
    "5. Try to normalize the datasets<br />\n",
    "6. Test for normality. Attempting to fit a linear regression is usually performed only if normality is passed.<br />\n",
    "7. Run linear regression model and test for goodness-of-fit using pearson's R.<br />\n",
    "7. If the pearson's R looks reasonable (here, we have to decide what is reasonable) and a linear relationship is found, then we should perform more rigorous tesing of assumptions as listed here:<br />\n",
    "    + Linearity<br />\n",
    "    + Homoscedasticity (Constant Variance)<br />\n",
    "    + Normality<br />\n",
    "    + Independence of Error<br />\n",
    "    + Outlier and Influential Observation Analysis<br />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy as scp\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from math import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#Define all function calls before main                               #\n",
    "######################################################################\n",
    "\n",
    "#######################################################\n",
    "#function calls for finding best pdf by SSE comparison\n",
    "#######################################################\n",
    "\n",
    "def best_fit_distribution(data, bins=200, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Distributions to check\n",
    "    \"\"\"\n",
    "    DISTRIBUTIONS = [        \n",
    "        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n",
    "        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n",
    "        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n",
    "        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n",
    "        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n",
    "        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n",
    "        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n",
    "        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n",
    "        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    DISTRIBUTIONS = [        \n",
    "        'dgamma','dweibull','expon','exponnorm','exponweib','exponpow','foldnorm','gamma','gengamma',\n",
    "        'halfnorm','halfgennorm','invgamma','invweibull','loggamma','lognorm','norm','powerlognorm',\n",
    "        'powernorm','weibull_min','weibull_max']\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for dist_name in DISTRIBUTIONS:\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "\n",
    "                # fit dist to data\n",
    "                distribution = getattr(st, dist_name)\n",
    "                if \"weibull\" in dist_name:\n",
    "                    params = distribution.fit(data.iloc[:,0], floc=0, f0=1) #have to convert dataframe to series\n",
    "                elif \"gamma\" in dist_name:\n",
    "                    params = distribution.fit(data, floc=0)\n",
    "                elif \"lognorm\" in dist_name:\n",
    "                    params = distribution.fit(data, floc=0)\n",
    "                else:\n",
    "                    params = distribution.fit(data)\n",
    "                print(dist_name, \" distribution parameters: \", params)\n",
    "                \n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "\n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "                print(\"SSE for \", dist_name, \": \", sse)\n",
    "\n",
    "                # if axis pass in add to plot\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    end\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                if best_sse > sse > 0:\n",
    "                    best_distribution = distribution\n",
    "                    best_params = params\n",
    "                    best_sse = sse\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return (best_distribution.name, best_params)\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "############################################################\n",
    "#function call to compute cohen's d for independent samples\n",
    "############################################################\n",
    "#for an overview of effect size computation: https://www.leeds.ac.uk/educol/documents/00002182.htm\n",
    "#Pooled standard deviation is used to account for difference in variation between the 2 samples\n",
    "#However, the use of a pooled estimate of standard deviation depends\n",
    "#on the assumption that the two calculated standard deviations are estimates of the same population value\n",
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "################################################################\n",
    "#function calls to compute cliff's delta for independent samples\n",
    "################################################################\n",
    "#for another overview of effect size: http://www.maths.dur.ac.uk/~dma0je/PG/TrainingWeek10/RSC-2010.pdf\n",
    "def cliffsDelta(lst1, lst2, **dull):\n",
    "#this function def is downloaded from https://github.com/neilernst/cliffsDelta; need to verify for correctness\n",
    "    \"\"\"Returns delta and true if there are more than 'dull' differences\"\"\"\n",
    "    if not dull:\n",
    "        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474} # effect sizes from (Hess and Kromrey, 2004)\n",
    "    m, n = len(lst1), len(lst2)\n",
    "    lst2 = sorted(lst2)\n",
    "    j = more = less = 0\n",
    "    for repeats, x in runs(sorted(lst1)):\n",
    "        while j <= (n - 1) and lst2[j] < x:\n",
    "            j += 1\n",
    "        more += j*repeats\n",
    "        while j <= (n - 1) and lst2[j] == x:\n",
    "            j += 1\n",
    "        less += (n - j)*repeats\n",
    "    d = (more - less) / (m*n)\n",
    "    size = lookup_size(d, dull)\n",
    "    return d, size\n",
    "\n",
    "\n",
    "def lookup_size(delta: float, dull: dict) -> str:\n",
    "    \"\"\"\n",
    "    :type delta: float\n",
    "    :type dull: dict, a dictionary of small, medium, large thresholds.\n",
    "    \"\"\"\n",
    "    delta = abs(delta)\n",
    "    if delta < dull['small']:\n",
    "        return 'negligible'\n",
    "    if dull['small'] <= delta < dull['medium']:\n",
    "        return 'small'\n",
    "    if dull['medium'] <= delta < dull['large']:\n",
    "        return 'medium'\n",
    "    if delta >= dull['large']:\n",
    "        return 'large'\n",
    "\n",
    "\n",
    "def runs(lst):\n",
    "    \"\"\"Iterator, chunks repeated values\"\"\"\n",
    "    for j, two in enumerate(lst):\n",
    "        if j == 0:\n",
    "            one, i = two, 0\n",
    "        if one != two:\n",
    "            yield j - i, one\n",
    "            i = j\n",
    "        one = two\n",
    "    yield j - i + 1, two\n",
    "\n",
    "############################################################\n",
    "#function call to identify outliers using Z-Score method\n",
    "############################################################\n",
    "\n",
    "#The intuition behind Z-score is to describe any data point by finding their relationship \n",
    "#with the Standard Deviation and Mean of the group of data points.\n",
    "#Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\n",
    "#while calculating the Z-score we re-scale and center the data and look for data points which are too far from zero.\n",
    "#These data points which are way too far from zero will be treated as the outliers.\n",
    "#In most of the cases a threshold of 3 or -3 is used\n",
    "#i.e if the Z-score value is greater than or less than 3 or -3 respectively, that data point will be identified as outliers.\n",
    "#99% of the data is retained(6 sigma = three standard deviations above and below the mean)\n",
    "\n",
    "def outliers_Z(d):\n",
    "    # calculate summary statistics\n",
    "    data_mean, data_std = np.mean(d), np.std(d)\n",
    "    # identify outliers\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    # identify outliers\n",
    "    outliers = [x for x in d if x < lower or x > upper]\n",
    "    print('Number of outliers: %d' % len(outliers))\n",
    "\n",
    "    # remove outliers\n",
    "    removed_outliers = [x for x in d if x >= lower and x <= upper]\n",
    "    print('No-outlier observations for dataset: %d' % len(removed_outliers))\n",
    "    return removed_outliers\n",
    "\n",
    "############################################################\n",
    "#function call to identify outliers using IQR method\n",
    "############################################################\n",
    "\n",
    "#It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\n",
    "#IQR is the middle 50% = Q3-Q1 \n",
    "#lower cutoff=(25th percentile - 150% of IQR); upper cutoff=(75th percentile + 150% of IQR)\n",
    "\n",
    "def outliers_IQR(d):    \n",
    "    # calculate interquartile range\n",
    "    q25, q75 = np.percentile(d, 25), np.percentile(d, 75)\n",
    "    iqr = q75 - q25\n",
    "    print('Percentiles for dataset: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "    # calculate the outlier cutoff\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    # identify outliers\n",
    "    outliers = [x for x in d if x < lower or x > upper]\n",
    "    print('Number of outliers: %d' % len(outliers))\n",
    "\n",
    "    # remove outliers using IQR\n",
    "    removed_outliers = [x for x in d if x >= lower and x <= upper]\n",
    "    print('No-outlier observations for dataset: %d' % len(removed_outliers))\n",
    "    return removed_outliers\n",
    "\n",
    "############################################################\n",
    "#function call to compute aic for regression\n",
    "############################################################\n",
    "\n",
    "def calculate_aic(n, mse, num_params):\n",
    "    aic = n * log(mse) + 2 * num_params\n",
    "    return aic\n",
    "\n",
    "############################################################\n",
    "#function call to compute bic for regression\n",
    "############################################################\n",
    "\n",
    "def calculate_bic(n, mse, num_params):\n",
    "    bic = n * log(mse) + num_params * log(n)\n",
    "    return bic\n",
    "\n",
    "#######################################################################\n",
    "#function call to normalize data using scaler & power transform\n",
    "#######################################################################\n",
    "\n",
    "##################\n",
    "#Quoted from part 2 section 16 of: http://www.faqs.org/faqs/ai-faq/neural-nets/part1/preamble.html\n",
    "#\"Rescaling\" a vector means to add or subtract a\n",
    "#constant and then multiply or divide by a constant, as you would do to\n",
    "#change the units of measurement of the data, for example, to convert a\n",
    "#temperature from Celsius to Fahrenheit. \n",
    "\n",
    "#\"Normalizing\" a vector most often means dividing by a norm of the vector,\n",
    "#for example, to make the Euclidean length of the vector equal to one. In the\n",
    "#NN literature, \"normalizing\" also often refers to rescaling by the minimum\n",
    "#and range of the vector, to make all the elements lie between 0 and 1. \n",
    "\n",
    "#\"Standardizing\" a vector most often means subtracting a measure of location\n",
    "#and dividing by a measure of scale. For example, if the vector contains\n",
    "#random values with a Gaussian distribution, you might subtract the mean and\n",
    "#divide by the standard deviation, thereby obtaining a \"standard normal\"\n",
    "#random variable with mean 0 and standard deviation 1. \n",
    "\n",
    "#However, all of the above terms are used more or less interchangeably\n",
    "#depending on the customs within various fields.\n",
    "##################\n",
    "\n",
    "##################\n",
    "#to learn more: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_map_data_to_normal.html\n",
    "#https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "#You can also consider the following transform functions available on scikit-learn:\n",
    "#mm_scaler = preprocessing.MinMaxScaler()\n",
    "#data = mm_scaler.fit_transform(d)\n",
    "\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#data = scaler.fit_transform(d)\n",
    "\n",
    "#transformer = preprocessing.RobustScaler()\n",
    "#data = transformer.fit_transform(d)\n",
    "\n",
    "#max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "#data = max_abs_scaler.fit_transform(pd.DataFrame(d))\n",
    "\n",
    "#power_xformer = preprocessing.PowerTransformer()\n",
    "#data_xformed = power_xformer.fit(data).transform(data)\n",
    "\n",
    "#data_xformed = preprocessing.power_transform(data, method='yeo-johnson')\n",
    "\n",
    "#data_xformed, lmbda = st.yeojohnson(data)\n",
    "\n",
    "#posdata = data[data > 0] #boxcox test uses strictly positive data only\n",
    "#data_xformed = st.boxcox(posdata, alpha)\n",
    "#################\n",
    "\n",
    "def xform(d):\n",
    "    data_xformed = preprocessing.power_transform(d, method='box-cox')\n",
    "    return data_xformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZTL dataset.shape:  (172423, 24)\n"
     ]
    }
   ],
   "source": [
    "#Read in data by ARTCC\n",
    "build_data = True\n",
    "TBFM_path = '<data directory here>'\n",
    "if build_data: \n",
    "    indiv_files = []\n",
    "    allFiles = glob.glob(os.path.join(TBFM_path, '*ZTL*.csv'),recursive=True)\n",
    "    allFiles = np.sort(allFiles)\n",
    "    for f in allFiles:\n",
    "        #print(f)\n",
    "        df = pd.read_csv(f, delim_whitespace=False, dtype={'acid': str, 'streamClass': str, 'FinalDelay': float, 'meterFixDistance': float})\n",
    "        df = df.dropna(axis=0, subset=['acid', 'streamClass', 'FinalDelay', 'meterFixDistance', 'coordinationTimeZulu'])\n",
    "        df = df[(df['FinalDelay'] != 0)]\n",
    "        indiv_files.append(df)\n",
    "     \n",
    "    df_ZTL = pd.concat(indiv_files)\n",
    "\n",
    "    #format specific fields with data type as int\n",
    "    df_ZTL['FinalDelay'] = df_ZTL['FinalDelay'].astype(int)\n",
    "    df_ZTL['meterFixDistance'] = df_ZTL['meterFixDistance'].astype(float)\n",
    "    df_ZTL['meterFixDistance'] = df_ZTL['meterFixDistance'].abs()\n",
    "    df_ZTL['coordinationTimeZulu'] = df_ZTL['coordinationTimeZulu'].astype(str)\n",
    "    df_ZTL.sort_values(by = 'streamClass')\n",
    "    \n",
    "    df_ZTL.to_csv('Dataset_ZTL.csv')\n",
    "    print(\"ZTL dataset.shape: \", df_ZTL.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute stats for delay per streamclass\n",
    "subset_delay = df_ZTL[['origApt', 'streamClass', 'FinalDelay', 'coordinationTimeZulu']]\n",
    "strClass_delay = pd.melt(subset_delay, id_vars='streamClass', value_vars='FinalDelay')\n",
    "strClass_delay_pivot = strClass_delay.pivot(columns='streamClass', values='value')\n",
    "delay_ZTL = strClass_delay_pivot.describe()\n",
    "delay_ZTL.transpose().to_csv('Delay_by_Streamclass_Statistic_ZTL.csv')\n",
    "\n",
    "#Compute stats for distance to meter fix per streamclass\n",
    "subset_dist = df_ZTL[['origApt', 'streamClass', 'meterFixDistance', 'coordinationTimeZulu']]\n",
    "strClass_dist = pd.melt(subset_dist, id_vars='streamClass', value_vars='meterFixDistance')\n",
    "strClass_dist_pivot = strClass_dist.pivot(columns='streamClass', values='value')\n",
    "dist_ZTL = strClass_dist_pivot.describe()\n",
    "dist_ZTL.transpose().to_csv('meterFixDist_by_Streamclass_Statistic_ZTL.csv')\n",
    "\n",
    "#We will pick ORD_DOOGE for this example\n",
    "subset_ORDDOOGE = df_ZTL[df_ZTL['streamClass']=='ORD_DOOGE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################################################################\n",
    "#If you want to set the median value of meterFixDistance from each airport     #\n",
    "#set the median value for each airport here, convert this cell type to \"code\"  #\n",
    "################################################################################\n",
    "\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'AGS', ['meterFixDistance']] = 223\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'ATL', ['meterFixDistance']] = 295\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'AVL', ['meterFixDistance']] = 94\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'BHM', ['meterFixDistance']] = 347\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'CAE', ['meterFixDistance']] = 215.1\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'CHS', ['meterFixDistance']] = 275\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'CLT', ['meterFixDistance']] = 142.6\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'GSO', ['meterFixDistance']] = 140\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'GSP', ['meterFixDistance']] = 139.3\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'GAI', ['meterFixDistance']] = 161\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'GSO', ['meterFixDistance']] = 390\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'JAX', ['meterFixDistance']] = 400\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'MCO', ['meterFixDistance']] = 520\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'MYR', ['meterFixDistance']] = 267\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'RDU', ['meterFixDistance']] = 214.3\n",
    "subset_ORDDOOGE.loc[subset_ORDDOOGE['origApt'] == 'SAV', ['meterFixDistance']] = 310\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data for streamclasses plots\n",
    "\n",
    "#drop stream classes with less than 10 counts for ZTL center, run once only or restart kernel\n",
    "#it'll throw errors if it can't find these streamclasses in the data\n",
    "strClass_delay_pivot = strClass_delay_pivot.drop(columns= [\n",
    "    'BWI_TONIO',\n",
    "    'DTW_IIU',\n",
    "    'EWR_J43_ROD',\n",
    "    'E_DTW_SUBWY',\n",
    "    'FLL_JEFOI',\n",
    "    'FLL_Q75',\n",
    "    'IAD_J83_APE',\n",
    "    'LGA_TONIO',\n",
    "    'MEM_MATCN',\n",
    "    'MIA_JEFOI',\n",
    "    'MLLET_RASLN_NAVEE_JET',\n",
    "    'MSP_BNA',\n",
    "    'TEB_PSK',\n",
    "    'TEB_TWINS',\n",
    "    'TPA_ACORI',\n",
    "    'BOS_Q22',\n",
    "    'DAL_PUDJE',\n",
    "    'DCA_J83_APE',\n",
    "    'LGA_TWINS',\n",
    "    'MCO_JEFOI',\n",
    "    'MMU_Q22',\n",
    "    'OTHR_AG1',\n",
    "    'SPARE_13',\n",
    "    'DAL_MEM',\n",
    "    'DTW_JAMOX',\n",
    "    'HOU_MEI',\n",
    "    'IAD_TWINS',\n",
    "    'JFK_J43_ROD',\n",
    "    'MCO_AREA4_PIE',\n",
    "    'OTHR_DN1',\n",
    "    'TPA_JEFOI',\n",
    "    'W_DTW_SUBWY',\n",
    "    'IAH_MEI',\n",
    "    'IAH_Q40_MEI',\n",
    "    'SPARE_6',\n",
    "    'IAH_MEM',\n",
    "    'LGA_J43_ROD',\n",
    "    'RSW_HONID',\n",
    "    'DCA_TONIO',\n",
    "    'MCO_Q75',\n",
    "    'OTHR_MHZ',\n",
    "    'OTHR_SJI',\n",
    "    'MIA_Q75',\n",
    "    'ROME_TURBO_PROP',\n",
    "    'OTHR_MGM',\n",
    "    'ROME_PISTON',\n",
    "    'TPA_HONID'])\n",
    "\n",
    "strClass_dist_pivot = strClass_dist_pivot.drop(columns= [\n",
    "    'BWI_TONIO',\n",
    "    'DTW_IIU',\n",
    "    'EWR_J43_ROD',\n",
    "    'E_DTW_SUBWY',\n",
    "    'FLL_JEFOI',\n",
    "    'FLL_Q75',\n",
    "    'IAD_J83_APE',\n",
    "    'LGA_TONIO',\n",
    "    'MEM_MATCN',\n",
    "    'MIA_JEFOI',\n",
    "    'MLLET_RASLN_NAVEE_JET',\n",
    "    'MSP_BNA',\n",
    "    'TEB_PSK',\n",
    "    'TEB_TWINS',\n",
    "    'TPA_ACORI',\n",
    "    'BOS_Q22',\n",
    "    'DAL_PUDJE',\n",
    "    'DCA_J83_APE',\n",
    "    'LGA_TWINS',\n",
    "    'MCO_JEFOI',\n",
    "    'MMU_Q22',\n",
    "    'OTHR_AG1',\n",
    "    'SPARE_13',\n",
    "    'DAL_MEM',\n",
    "    'DTW_JAMOX',\n",
    "    'HOU_MEI',\n",
    "    'IAD_TWINS',\n",
    "    'JFK_J43_ROD',\n",
    "    'MCO_AREA4_PIE',\n",
    "    'OTHR_DN1',\n",
    "    'TPA_JEFOI',\n",
    "    'W_DTW_SUBWY',\n",
    "    'IAH_MEI',\n",
    "    'IAH_Q40_MEI',\n",
    "    'SPARE_6',\n",
    "    'IAH_MEM',\n",
    "    'LGA_J43_ROD',\n",
    "    'RSW_HONID',\n",
    "    'DCA_TONIO',\n",
    "    'MCO_Q75',\n",
    "    'OTHR_MHZ',\n",
    "    'OTHR_SJI',\n",
    "    'MIA_Q75',\n",
    "    'ROME_TURBO_PROP',\n",
    "    'OTHR_MGM',\n",
    "    'ROME_PISTON',\n",
    "    'TPA_HONID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into before and after APREQ prescheduling to ORD was turned on in June 2019\n",
    "\n",
    "ORD_preAPREQ = datetime.strptime(\"20190601 00:00:00\", \"%Y%m%d %H:%M:%S\")\n",
    "ORD_pstAPREQ = datetime.strptime(\"20190701 00:00:00\", \"%Y%m%d %H:%M:%S\")\n",
    "\n",
    "subset_ORDDOOGE_preAPREQ = subset_ORDDOOGE[subset_ORDDOOGE['coordinationTimeZulu'].apply(lambda x: datetime.strptime(x, '%Y%m%d %H:%M:%S')) < ORD_preAPREQ]\n",
    "subset_ORDDOOGE_pstAPREQ = subset_ORDDOOGE[subset_ORDDOOGE['coordinationTimeZulu'].apply(lambda x: datetime.strptime(x, '%Y%m%d %H:%M:%S')) >= ORD_pstAPREQ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORD_DOOGE delay statistics before APREQ Prescheduling:\n",
      " count    1754.000000\n",
      "mean       12.692702\n",
      "std        10.528623\n",
      "min         1.000000\n",
      "25%         5.000000\n",
      "50%         9.000000\n",
      "75%        18.000000\n",
      "max        61.000000\n",
      "Name: FinalDelay, dtype: float64\n",
      "\n",
      "\n",
      "ORD_DOOGE delay statistics after APREQ Prescheduling:\n",
      " count    2465.000000\n",
      "mean       13.335091\n",
      "std        11.057392\n",
      "min         1.000000\n",
      "25%         5.000000\n",
      "50%        10.000000\n",
      "75%        18.000000\n",
      "max        86.000000\n",
      "Name: FinalDelay, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Compute stats for delay per airport & streamclass before & after APREQ prescheduling to ORD\n",
    "print(\"ORD_DOOGE delay statistics before APREQ Prescheduling:\\n\", subset_ORDDOOGE_preAPREQ['FinalDelay'].describe())\n",
    "print(\"\\n\")\n",
    "print(\"ORD_DOOGE delay statistics after APREQ Prescheduling:\\n\", subset_ORDDOOGE_pstAPREQ['FinalDelay'].describe())\n",
    "\n",
    "origApt_delay_ORDDOOGE_preAPREQ = pd.melt(subset_ORDDOOGE_preAPREQ, id_vars='origApt', value_vars='FinalDelay')\n",
    "origApt_delay_ORDDOOGE_preAPREQ_pivot = origApt_delay_ORDDOOGE_preAPREQ.pivot(columns='origApt', values='value')\n",
    "origApt_delay_ORDDOOGE_preAPREQ_pivot = origApt_delay_ORDDOOGE_preAPREQ_pivot.loc[:, origApt_delay_ORDDOOGE_preAPREQ_pivot.columns.notnull()]\n",
    "delay_ORDDOOGE_preAPREQ = origApt_delay_ORDDOOGE_preAPREQ_pivot.describe()\n",
    "delay_ORDDOOGE_preAPREQ.transpose().to_csv('Delay_by_Airports_to_ORD_DOOGE_preAPREQ_statistics.csv')\n",
    "\n",
    "origApt_delay_ORDDOOGE_pstAPREQ = pd.melt(subset_ORDDOOGE_pstAPREQ, id_vars='origApt', value_vars='FinalDelay')\n",
    "origApt_delay_ORDDOOGE_pstAPREQ_pivot = origApt_delay_ORDDOOGE_pstAPREQ.pivot(columns='origApt', values='value')\n",
    "origApt_delay_ORDDOOGE_pstAPREQ_pivot = origApt_delay_ORDDOOGE_pstAPREQ_pivot.loc[:, origApt_delay_ORDDOOGE_pstAPREQ_pivot.columns.notnull()]\n",
    "delay_ORDDOOGE_pstAPREQ = origApt_delay_ORDDOOGE_pstAPREQ_pivot.describe()\n",
    "delay_ORDDOOGE_pstAPREQ.transpose().to_csv('Delay_by_Airports_to_ORD_DOOGE_pstAPREQ_statistics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#Plot delays and meterFixDistance for streamclasses in the ARTCC  #\n",
    "###################################################################\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ZTL_plots.pdf\")\n",
    "\n",
    "# histograms\n",
    "strClass_delay_pivot.hist(sharex=False, sharey=False, xlabelsize=.2, ylabelsize=.2, figsize=(40, 24), bins=50)\n",
    "plt.suptitle(\"Histograms - Delays - ZTL center\", fontsize=50)\n",
    "pdf.savefig()\n",
    "\n",
    "strClass_dist_pivot.hist(sharex=False, sharey=False, xlabelsize=.2, ylabelsize=.2, figsize=(40, 24), bins=50)\n",
    "plt.suptitle(\"Histograms - Meter Fix Distance - ZTL center\", fontsize=50)\n",
    "pdf.savefig()\n",
    "\n",
    "# density\n",
    "strClass_delay_pivot.plot(kind='density', subplots=True, figsize=(40,24), layout=(10,10), sharex=False, sharey=False, legend=False, fontsize=.2)\n",
    "plt.suptitle(\"KDE - Delays - ZTL center\", fontsize=50)\n",
    "pdf.savefig()\n",
    "\n",
    "strClass_dist_pivot.plot(kind='density', subplots=True, figsize=(40,24), layout=(10,10), sharex=False, sharey=False, legend=False, fontsize=.2)\n",
    "plt.suptitle(\"KDE - Distance to the Meter Fix - ZTL center\", fontsize=50)\n",
    "pdf.savefig()\n",
    "\n",
    "#boxplots\n",
    "strClass_delay_pivot.plot(kind='box', subplots=True, figsize=(40,24), layout=(10,10), sharex=False, sharey=False, fontsize=.2)\n",
    "plt.suptitle(\"Box & Whisker Plot - Delays - ZTL center\", fontsize=50)\n",
    "pdf.savefig()\n",
    "\n",
    "strClass_dist_pivot.plot(kind='box', subplots=True, figsize=(40,24), layout=(10,10), sharex=False, sharey=False, fontsize=.2)\n",
    "plt.suptitle(\"Box & Whisker Plot - Distance to the Meter Fix - ZTL center\", fontsize=50)\n",
    "pdf.savefig()\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO ADDRESS THE FIRST QUESTION:<br />  \n",
    "\n",
    "We will assess whether there are statistically significant differences between the delay before vs. after APREQ pre-scheduling. <br />\n",
    "We will assess overall delay for ORD_DOOGE streamclass and delay for each airport going to ORD_DOOGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#Plots for raw data per streamclass before & after APREQ prescheduling to ORD #\n",
    "###############################################################################\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_Plots_RawData.pdf\")\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "#Scatter plots\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "ax1 = sns.scatterplot(subset_ORDDOOGE_preAPREQ['meterFixDistance'], subset_ORDDOOGE_preAPREQ['FinalDelay'], edgecolor='none',\n",
    "                  hue=subset_ORDDOOGE_preAPREQ['FinalDelay'], size=subset_ORDDOOGE_preAPREQ['meterFixDistance'],\n",
    "                      linewidth=0, alpha = 1, ax=axs[0])\n",
    "sns.dark_palette(\"muted purple\", input=\"xkcd\")\n",
    "ax1.set_title('Scatter plot for ORD_DOOGE\\n before APREQ prescheduling - raw data')\n",
    "ax1.set_xlabel('Meter Fix Distance (nm)')\n",
    "ax1.set_ylabel('Delay (minutes)')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "ax2 = sns.scatterplot(subset_ORDDOOGE_pstAPREQ['meterFixDistance'], subset_ORDDOOGE_pstAPREQ['FinalDelay'], edgecolor='none',\n",
    "                  hue=subset_ORDDOOGE_pstAPREQ['FinalDelay'], size=subset_ORDDOOGE_pstAPREQ['meterFixDistance'],\n",
    "                      linewidth=0, alpha = 1, ax=axs[1])\n",
    "sns.dark_palette(\"palegreen\", as_cmap=True)\n",
    "ax2.set_title('Scatter plot for ORD_DOOGE\\n after APREQ prescheduling - raw data')\n",
    "ax2.set_xlabel('Meter Fix Distance (nm)')\n",
    "ax2.set_ylabel('Delay (minutes)')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "pdf.savefig()\n",
    "\n",
    "#Histograms\n",
    "bins=np.linspace(0, 100, 50)\n",
    "plt.figure()\n",
    "plt.hist(subset_ORDDOOGE_preAPREQ['FinalDelay'], bins=bins, alpha=.5, label='before')\n",
    "plt.hist(subset_ORDDOOGE_pstAPREQ['FinalDelay'], bins=bins, alpha=.5, label='after')\n",
    "plt.legend(loc='upper right')\n",
    "plt.suptitle(\"Histograms - ORD_DOOGE\\nDelays before and after APREQ pre-scheduling\", fontsize=15)\n",
    "pdf.savefig()\n",
    "    \n",
    "#Density\n",
    "plt.figure()\n",
    "sns.distplot(subset_ORDDOOGE_preAPREQ['FinalDelay'], hist = False, kde = True,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3}, label='Before')\n",
    "sns.distplot(subset_ORDDOOGE_pstAPREQ['FinalDelay'], hist = False, kde = True,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3}, label='After')\n",
    "plt.legend(loc='upper right')\n",
    "plt.suptitle(\"Density Plot - ORD_DOOGE\\nDelays before and after APREQ pre-scheduling\", fontsize=15)\n",
    "pdf.savefig()\n",
    "    \n",
    "#Boxplots\n",
    "plt.figure()\n",
    "\n",
    "#To prevent multiple boxes being plotted on top of each other:\n",
    "#1st make tuples\n",
    "np1=subset_ORDDOOGE_preAPREQ['FinalDelay'].to_numpy()\n",
    "np_pre=[]\n",
    "new_col1=np.zeros(np1.size) #pre APREQ-prescheduling data is marked status=0\n",
    "for x,y in zip(np1, new_col1):\n",
    "    np_pre.append([x,y])\n",
    "np2=subset_ORDDOOGE_pstAPREQ['FinalDelay'].to_numpy()\n",
    "np_pst=[]\n",
    "new_col2 = np.ones(np2.size) #post APREQ-prescheduling data is marked status=1\n",
    "for x,y in zip(np2, new_col2):\n",
    "    np_pst.append([x,y])\n",
    "np3=np.concatenate((np_pre, np_pst), axis=0) #concat 2 sets of data into one array\n",
    "    \n",
    "#then turn tuples into a list\n",
    "list1=[[float(pair[0]) for pair in np3], [float(pair[1]) for pair in np3]]\n",
    "    \n",
    "#then turn the list into a dataframe\n",
    "subset_ORDDOOGE_byAPREQdate=pd.DataFrame(list(zip(list1[0], list1[1])),\n",
    "                            columns=['Delay', 'Status'])\n",
    "subset_ORDDOOGE_byAPREQdate.loc[subset_ORDDOOGE_byAPREQdate['Status'] == 0, ['Status']] = 'Before APREQ Pre-scheduling'\n",
    "subset_ORDDOOGE_byAPREQdate.loc[subset_ORDDOOGE_byAPREQdate['Status'] == 1, ['Status']] = 'After APREQ Pre-scheduling'\n",
    "\n",
    "#finally use the dataframe to create the boxplot, so that the 2 sets of data are not on top of each other\n",
    "sns.boxplot(y='Delay', x='Status', data=subset_ORDDOOGE_byAPREQdate, palette=\"colorblind\", hue='Status')\n",
    "plt.legend(loc='upper right')\n",
    "plt.suptitle(\"Boxplot - ORD_DOOGE\\nDelays before and after APREQ pre-scheduling\", fontsize=15)\n",
    "\n",
    "pdf.savefig()\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers using Z method for ORD_DOOGE delay data before APREQ prescheduling:\n",
      "Number of outliers: 18\n",
      "No-outlier observations for dataset: 1736\n",
      "Identified outliers using Z method for ORD_DOOGE delay data after APREQ prescheduling:\n",
      "Number of outliers: 37\n",
      "No-outlier observations for dataset: 2428\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "D'sub.05 for delay data w/ sample size of 868  =  0.04616140786454489\n",
      "KS test results against normal dist: D =  0.9780736121441449 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9801141023635864 p =  1.7176799982365765e-09\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality: normalized delay distribution for ORD_DOOGE after APREQ-prescheduling\n",
      "D'sub.05 for delay data w/ sample size of 1214  =  0.039032787299259825\n",
      "KS test results against normal dist: D =  0.9828161847875245 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9831337928771973 p =  1.1334940624996293e-10\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for ORD_DOOGE:***\n",
      "\n",
      "Sample sizes - Before: 1736 ; After: 2428\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 1736 2428  =  0.04274595922649371\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.04574036395660459 p =  0.02781214127836884\n",
      "2 sample KS test results for normalized data : D =  0.05846442047085083 p =  0.0018745599566492022\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  1.7765534820840855e-14 p =  0.9999999999999858\n",
      "The null hypothesis is rejected if T > 1.96 and p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "\n",
      "If data distributions pass normality test, compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "-0.04417366376700114\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size uisng Cliff's Delta:\n",
      "(-0.02877432261101284, 'negligible')\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "#Remove outliers for streamclass ORD_DOOGE before and after APREQ prescheduling  #\n",
    "#Then run statistical tests to compare delay distributions between               #\n",
    "#pre and post APREQ prescheduling                                                #\n",
    "##################################################################################\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_PDF_PP_Plots.pdf\")\n",
    " \n",
    "#######################\n",
    "#identify outliers using Z for preAPREQ set\n",
    "print(\"Identified outliers using Z method for ORD_DOOGE delay data before APREQ prescheduling:\")\n",
    "subset_delay_ORDDOOGE_preAPREQ_noO = pd.DataFrame(outliers_Z(subset_ORDDOOGE_preAPREQ['FinalDelay']))\n",
    "\n",
    "#######################\n",
    "#identify outliers using Z for pstAPREQ set\n",
    "print(\"Identified outliers using Z method for ORD_DOOGE delay data after APREQ prescheduling:\")\n",
    "subset_delay_ORDDOOGE_pstAPREQ_noO = pd.DataFrame(outliers_Z(subset_ORDDOOGE_pstAPREQ['FinalDelay']))\n",
    "\n",
    "X_train_delay_ORDDOOGE_preAPREQ, X_test_delay_ORDDOOGE_preAPREQ = train_test_split(subset_delay_ORDDOOGE_preAPREQ_noO,test_size=.5)\n",
    "X_train_delay_ORDDOOGE_preAPREQ = X_train_delay_ORDDOOGE_preAPREQ.astype(int)\n",
    "X_test_delay_ORDDOOGE_preAPREQ = X_test_delay_ORDDOOGE_preAPREQ.astype(int)\n",
    "\n",
    "X_train_delay_ORDDOOGE_pstAPREQ, X_test_delay_ORDDOOGE_pstAPREQ = train_test_split(subset_delay_ORDDOOGE_pstAPREQ_noO,test_size=.5)\n",
    "X_train_delay_ORDDOOGE_pstAPREQ = X_train_delay_ORDDOOGE_pstAPREQ.astype(int)\n",
    "X_test_delay_ORDDOOGE_pstAPREQ = X_test_delay_ORDDOOGE_pstAPREQ.astype(int)\n",
    "\n",
    "#For each airport, run KS test against a normal dist on the test dataset using params derived from train dataset\n",
    "#For an overview of the KS test: \n",
    "#https://www.statisticshowto.datasciencecentral.com/kolmogorov-smirnov-test/\n",
    "\n",
    "X_train_delay_ORDDOOGE_preAPREQ_xformed = xform(X_train_delay_ORDDOOGE_preAPREQ)\n",
    "X_test_delay_ORDDOOGE_preAPREQ_xformed = xform(X_test_delay_ORDDOOGE_preAPREQ)\n",
    "\n",
    "s = pd.DataFrame(X_train_delay_ORDDOOGE_preAPREQ_xformed).describe(include='all')\n",
    "X_train_delay_ORDDOOGE_preAPREQ_fit_params = [s.loc['mean'], s.loc['std']]\n",
    "\n",
    "#Here, we will evaluate normality using both the test statistic's critical value and p-value\n",
    "#Critical value is a point beyond which we reject the null hypothesis.\n",
    "#P-value on the other hand is defined as the probability to the right of respective statistic (Z, T or chi). \n",
    "#The benefit of using p-value is that it calculates a probability estimate, \n",
    "#we can test at any desired level of significance by comparing this probability directly with the significance level.\n",
    "print(\"\\n***Test data distributions for normality:***\")\n",
    "statTest, pTest = st.kstest(X_test_delay_ORDDOOGE_preAPREQ_xformed, 'norm', args=(X_train_delay_ORDDOOGE_preAPREQ_fit_params))\n",
    "sizeX_test = len(X_test_delay_ORDDOOGE_preAPREQ_xformed)\n",
    "print(\"Test for normality using KS: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\")\n",
    "print(\"D'sub.05 for delay data w/ sample size of\", sizeX_test, \" = \", 1.36/np.sqrt(sizeX_test))\n",
    "print(\"KS test results against normal dist: D = \", statTest, \"p = \", pTest)\n",
    "print(\"The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\\n\")\n",
    "\n",
    "#Try testing against normality using shapiro-wilk; we'll see that it works better for large sample sizes\n",
    "#It looks like since critical value for W is harder to compute, evaluate p-value only\n",
    "statTest, pTest = st.shapiro(X_test_delay_ORDDOOGE_preAPREQ_xformed)\n",
    "print(\"Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\")\n",
    "print(\"Shapiro-Wilk test results against normal dist: W = \", statTest, \"p = \", pTest)\n",
    "print(\"The null hypothesis is rejected if p < alpha=.05\")\n",
    "\n",
    "X_train_delay_ORDDOOGE_pstAPREQ_xformed = xform(X_train_delay_ORDDOOGE_pstAPREQ)\n",
    "X_test_delay_ORDDOOGE_pstAPREQ_xformed = xform(X_test_delay_ORDDOOGE_pstAPREQ)\n",
    "        \n",
    "s = pd.DataFrame(X_train_delay_ORDDOOGE_pstAPREQ_xformed).describe(include='all')\n",
    "X_train_delay_ORDDOOGE_pstAPREQ_fit_params = [s.loc['mean'], s.loc['std']]\n",
    "   \n",
    "statTest, pTest = st.kstest(X_test_delay_ORDDOOGE_pstAPREQ_xformed, 'norm', args=(X_train_delay_ORDDOOGE_pstAPREQ_fit_params))\n",
    "sizeX_test = len(X_test_delay_ORDDOOGE_pstAPREQ_xformed)\n",
    "print(\"\\nTest for normality: normalized delay distribution for ORD_DOOGE after APREQ-prescheduling\")\n",
    "print (\"D'sub.05 for delay data w/ sample size of\", sizeX_test, \" = \", 1.36/np.sqrt(sizeX_test))\n",
    "print(\"KS test results against normal dist: D = \", statTest, \"p = \", pTest)\n",
    "print(\"The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\\n\")\n",
    "\n",
    "statTest, pTest = st.shapiro(X_test_delay_ORDDOOGE_pstAPREQ_xformed)\n",
    "print(\"Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\")\n",
    "print(\"Shapiro-Wilk test results against normal dist: W = \", statTest, \"p = \", pTest)\n",
    "print(\"The null hypothesis is rejected if p < alpha=.05\")\n",
    "\n",
    "#P-P plots and histograms for normality assessment\n",
    "left = -1.8   #x coordinate for text insert\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "prob= st.probplot(X_test_delay_ORDDOOGE_preAPREQ_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "ax.set_title('PP Plot:ORD_DOOGE delays before APREQ prescheduling against a normal dist')\n",
    "top = ax.get_ylim()[1] * 0.75\n",
    "txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "prob = plt.hist(X_test_delay_ORDDOOGE_preAPREQ_xformed)\n",
    "ax.set_title('Normalized ORD_DOOGE delays before APREQ prescheduling')\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "prob = st.probplot(X_test_delay_ORDDOOGE_pstAPREQ_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "ax.set_title('PP Plot:ORD_DOOGE delays after APREQ prescheduling against a normal dist')\n",
    "top = ax.get_ylim()[1] * 0.75\n",
    "txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "prob = plt.hist(X_test_delay_ORDDOOGE_pstAPREQ_xformed)\n",
    "ax.set_title('Normalized ORD_DOOGE delays after APREQ prescheduling')\n",
    "    \n",
    "pdf.savefig()\n",
    "\n",
    "##################################################################################\n",
    "#Then compare the delay distribution before vs. after APREQ pre-scheduling to\n",
    "#assess for statistically significant differences between the two.\n",
    "#If test for normality run above passes, then use the Welch's T-test, which is the student-T test\n",
    "#accounting for unequal variances. Here's an interesting blog post about the Welch's T-test:\n",
    "#http://daniellakens.blogspot.com/2015/01/always-use-welchs-t-test-instead-of.html\n",
    "#If test for normality above does not pass, then use KS test.\n",
    "\n",
    "#If there is a statistically significant difference, then assess the effect size\n",
    "#A small p (â‰¤ alpha = .05), reject the null hypothesis.\n",
    "#A large p (> alpha = .05) accept the null hypothesis\n",
    "\n",
    "print(\"\\n***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for ORD_DOOGE:***\\n\")\n",
    "#1st try to normalize the dataset for pre & post APREQ prescheduling \n",
    "subset_delay_ORDDOOGE_preAPREQ_xformed = xform(subset_delay_ORDDOOGE_preAPREQ_noO)\n",
    "subset_delay_ORDDOOGE_pstAPREQ_xformed = xform(subset_delay_ORDDOOGE_pstAPREQ_noO)    \n",
    "    \n",
    "sizeX_2samp_test = len(subset_delay_ORDDOOGE_preAPREQ_noO)\n",
    "sizeY_2samp_test = len(subset_delay_ORDDOOGE_pstAPREQ_noO)\n",
    "    \n",
    "print(\"Sample sizes - Before:\", sizeX_2samp_test, \"; After:\", sizeY_2samp_test)\n",
    "statTest_delay_2samp_ks, pTest_delay_2samp_ks = st.ks_2samp(subset_delay_ORDDOOGE_preAPREQ_noO.iloc[:,0], subset_delay_ORDDOOGE_pstAPREQ_noO.iloc[:,0])\n",
    "statTest_delay_2samp_norm_ks, pTest_delay_2samp_norm_ks = st.ks_2samp(subset_delay_ORDDOOGE_preAPREQ_xformed.flatten(), subset_delay_ORDDOOGE_pstAPREQ_xformed.flatten())\n",
    "statTest_delay_2samp_norm_t, pTest_delay_2samp_norm_t = st.ttest_ind(subset_delay_ORDDOOGE_preAPREQ_xformed.flatten(), subset_delay_ORDDOOGE_pstAPREQ_xformed.flatten(), equal_var=False)\n",
    "\n",
    "\n",
    "print(\"Use KS test if normalized data distributions do not pass test for normality:\")\n",
    "print (\"D'sub.05 for dataset w/ sample sizes of\", sizeX_2samp_test, sizeY_2samp_test, \" = \", 1.36*np.sqrt((sizeX_2samp_test + sizeY_2samp_test)/(sizeX_2samp_test*sizeY_2samp_test)))\n",
    "print(\"2 sample KS test results for raw data w/o outliers : D = \", statTest_delay_2samp_ks, \"p = \", pTest_delay_2samp_ks)\n",
    "print(\"2 sample KS test results for normalized data : D = \", statTest_delay_2samp_norm_ks, \"p = \", pTest_delay_2samp_norm_ks)\n",
    "print(\"The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\")\n",
    "\n",
    "print(\"\\nUse Welch's T-test if normalized data distributions pass test for normality:\")\n",
    "print(\"2 sample Welch's T-test results for normalized data : T = \", statTest_delay_2samp_norm_t, \"p = \", pTest_delay_2samp_norm_t)\n",
    "print(\"The null hypothesis is rejected if T > 1.96 and p < alpha=.05\")\n",
    "print(\"If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\")\n",
    "print(\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\")\n",
    "\n",
    "    \n",
    "#compute the Cohen's D coefficient since sample sizes are different, use pearson if the sample sizes are the same\n",
    "print(\"\\n***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\")\n",
    "print(\"\\nIf data distributions pass normality test, compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\")\n",
    "print(cohend(subset_delay_ORDDOOGE_preAPREQ_noO.iloc[:,0], subset_delay_ORDDOOGE_pstAPREQ_noO.iloc[:,0]))\n",
    "\n",
    "#compute the Cliff's Delta coefficient if non-parametric distribution\n",
    "print(\"\\nIf data distributions do not pass normality test, compute effect size uisng Cliff's Delta:\")\n",
    "print(cliffsDelta(subset_delay_ORDDOOGE_preAPREQ_noO.iloc[:,0], subset_delay_ORDDOOGE_pstAPREQ_noO.iloc[:,0]))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#Plot delays before & after APREQ prescheduling for airports per streamclass #\n",
    "##############################################################################\n",
    "\n",
    "#origApt_delay_ORDDOOGE_preAPREQ.drop = ['ATL','MYR','MCO','AGS','JAX']\n",
    "#origApt_delay_ORDDOOGE_pstAPREQ.drop = ['BHM','GSO','MYR']\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "origAptList = [\n",
    "    'CHS',\n",
    "    'SAV',\n",
    "    'CAE',\n",
    "    'AVL',\n",
    "    'GSP',\n",
    "    'CLT',\n",
    "    'RDU']\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_Plots_byAirports.pdf\")\n",
    "\n",
    "bins=np.linspace(0, 100, 50)\n",
    "\n",
    "for aptName in origAptList:\n",
    "    subset_byAirport_ORDDOOGE_preAPREQ = subset_ORDDOOGE_preAPREQ[subset_ORDDOOGE_preAPREQ['origApt']==aptName]\n",
    "    subset_byAirport_ORDDOOGE_pstAPREQ = subset_ORDDOOGE_pstAPREQ[subset_ORDDOOGE_pstAPREQ['origApt']==aptName]\n",
    "\n",
    "    #Histograms\n",
    "    plt.figure()\n",
    "    plt.hist(subset_byAirport_ORDDOOGE_preAPREQ['FinalDelay'], bins=bins, alpha=.5, label='before')\n",
    "    plt.hist(subset_byAirport_ORDDOOGE_pstAPREQ['FinalDelay'], bins=bins, alpha=.5, label='after')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.suptitle(\"Histograms - \" + aptName + \" to ORD_DOOGE\\nDelays before and after APREQ pre-scheduling\", fontsize=15)\n",
    "    pdf.savefig()\n",
    "    \n",
    "    #Density\n",
    "    plt.figure()\n",
    "    sns.distplot(subset_byAirport_ORDDOOGE_preAPREQ['FinalDelay'], hist = False, kde = True,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3}, label='Before')\n",
    "    sns.distplot(subset_byAirport_ORDDOOGE_pstAPREQ['FinalDelay'], hist = False, kde = True,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3}, label='After')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.suptitle(\"Density Plot - \" + aptName + \" to ORD_DOOGE\\nDelays before and after APREQ pre-scheduling\", fontsize=15)\n",
    "    pdf.savefig()\n",
    "    \n",
    "    #Boxplot\n",
    "    plt.figure()\n",
    "    \n",
    "    #to prevent having the boxes being plotted on top of each other:\n",
    "    #1st make an array of tuples\n",
    "    np1=subset_byAirport_ORDDOOGE_preAPREQ['FinalDelay'].to_numpy()\n",
    "    np_pre=[]\n",
    "    new_col1=np.zeros(np1.size) #pre APREQ-prescheduling data is marked status=0\n",
    "    for x,y in zip(np1, new_col1):\n",
    "        np_pre.append([x,y])\n",
    "    np2=subset_byAirport_ORDDOOGE_pstAPREQ['FinalDelay'].to_numpy()\n",
    "    np_pst=[]\n",
    "    new_col2 = np.ones(np2.size) #post APREQ-prescheduling data is marked status=1\n",
    "    for x,y in zip(np2, new_col2):\n",
    "        np_pst.append([x,y])\n",
    "    np3=np.concatenate((np_pre, np_pst), axis=0) #concat 2 sets of data into one array\n",
    "    \n",
    "    #then turn the array of tuples into a list\n",
    "    list1=[[float(pair[0]) for pair in np3], [float(pair[1]) for pair in np3]]\n",
    "    \n",
    "    #then turn the list into a data frame\n",
    "    subset_DelayByAirport_ORDDOOGE_byAPREQdate=pd.DataFrame(list(zip(list1[0], list1[1])),\n",
    "                            columns=['Delay', 'Status'])\n",
    "    subset_DelayByAirport_ORDDOOGE_byAPREQdate.loc[subset_DelayByAirport_ORDDOOGE_byAPREQdate['Status'] == 0, ['Status']] = 'Before APREQ Pre-scheduling'\n",
    "    subset_DelayByAirport_ORDDOOGE_byAPREQdate.loc[subset_DelayByAirport_ORDDOOGE_byAPREQdate['Status'] == 1, ['Status']] = 'After APREQ Pre-scheduling'\n",
    "\n",
    "    #finally use the dataframe to create the boxplot, so that the 2 sets of data are not on top of each other\n",
    "    sns.boxplot(y='Delay', x='Status', data=subset_DelayByAirport_ORDDOOGE_byAPREQdate, palette=\"colorblind\", hue='Status')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.suptitle(\"Boxplot - \" + aptName + \" to ORD_DOOGE\\nDelays before and after APREQ pre-scheduling\", fontsize=15)\n",
    "    pdf.savefig()\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()\n",
    "                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport:  CHS\n",
      "Identified outliers using Z method for delay data for: CHS\n",
      "Number of outliers: 0\n",
      "No-outlier observations for dataset: 14\n",
      "Identified outliers using Z method for delay data for: CHS\n",
      "Number of outliers: 0\n",
      "No-outlier observations for dataset: 43\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n",
      "dweibull  distribution parameters:  (1, 0, 8.000011643863989)\n",
      "SSE for  dweibull :  11.88669162823157\n",
      "expon  distribution parameters:  (1.0, 7.0)\n",
      "SSE for  expon :  11.536028961302767\n",
      "gamma  distribution parameters:  (0.7892448488688286, 0, 10.13627141370116)\n",
      "SSE for  gamma :  11.565530482394141\n",
      "invweibull  distribution parameters:  (1, 0, 2.1440429687500027)\n",
      "SSE for  invweibull :  11.060943083696516\n",
      "lognorm  distribution parameters:  (1.2335757913352383, 0.0, 3.766405163294681)\n",
      "SSE for  lognorm :  11.313834634479413\n",
      "norm  distribution parameters:  (8.0, 9.54687682663064)\n",
      "SSE for  norm :  12.063631241494926\n",
      "weibull_min  distribution parameters:  (1, 0, 7.99999609471802)\n",
      "SSE for  weibull_min :  11.635756314235133\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  12.317684275356257\n",
      "dweibull  distribution parameters:  (1, 0, 11.71426384256981)\n",
      "SSE for  dweibull :  3.5716560638420507\n",
      "expon  distribution parameters:  (1.0, 10.714285714285714)\n",
      "SSE for  expon :  3.495532278294295\n",
      "gamma  distribution parameters:  (1.5812312545201972, 0, 7.408331754636517)\n",
      "SSE for  gamma :  3.516421428267758\n",
      "invweibull  distribution parameters:  (1, 0, 4.640136718750007)\n",
      "SSE for  invweibull :  3.6377584684970032\n",
      "lognorm  distribution parameters:  (0.9746482199211868, 0.0, 8.26819216166562)\n",
      "SSE for  lognorm :  3.5644461217414865\n",
      "norm  distribution parameters:  (11.714285714285714, 8.130734501717232)\n",
      "SSE for  norm :  3.5170156875632483\n",
      "weibull_min  distribution parameters:  (1, 0, 11.714257812500023)\n",
      "SSE for  weibull_min :  3.4917175272778493\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  3.7747956891833145\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for CHS before APREQ-prescheduling\n",
      "D'sub.05 for  CHS  delay dataset w/ sample size of 7  =  0.514031683292549\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.8922709248925156 p =  3.367910289019533e-07\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.8627865314483643 p =  0.16031716763973236\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for CHS after APREQ-prescheduling\n",
      "D'sub.05 for  CHS  delay dataset w/ sample size of 22  =  0.2899529742436302\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9785884162196395 p =  3.7610008508409515e-37\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.973453164100647 p =  0.7894224524497986\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  CHS ***\n",
      "\n",
      "Sample sizes - Before: 14 ; After: 43\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 14 43  =  0.41848326036134087\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.36212624584717606 p =  0.09943960898231852\n",
      "2 sample KS test results for normalized data : D =  0.19933554817275748 p =  0.7148018455051273\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  1.3085704272658247e-15 p =  0.9999999999999989\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "-0.3382683990387906\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(-0.29900332225913623, 'small')\n",
      "\n",
      "\n",
      "\n",
      "Airport:  SAV\n",
      "Identified outliers using Z method for delay data for: SAV\n",
      "Number of outliers: 0\n",
      "No-outlier observations for dataset: 14\n",
      "Identified outliers using Z method for delay data for: SAV\n",
      "Number of outliers: 2\n",
      "No-outlier observations for dataset: 46\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n",
      "dweibull  distribution parameters:  (1, 0, 9.857137685155621)\n",
      "SSE for  dweibull :  4.6824478437509685\n",
      "expon  distribution parameters:  (1.0, 8.857142857142858)\n",
      "SSE for  expon :  4.50925280790531\n",
      "gamma  distribution parameters:  (0.9307288890108669, 0, 10.590777801706087)\n",
      "SSE for  gamma :  4.534153992911543\n",
      "invweibull  distribution parameters:  (1, 0, 3.057226562500004)\n",
      "SSE for  invweibull :  4.426453270959172\n",
      "lognorm  distribution parameters:  (1.1376535517847937, 0.0, 5.273361925858103)\n",
      "SSE for  lognorm :  4.465440443984621\n",
      "norm  distribution parameters:  (9.857142857142858, 11.217697388228903)\n",
      "SSE for  norm :  4.760958208634378\n",
      "weibull_min  distribution parameters:  (1, 0, 9.857113388601922)\n",
      "SSE for  weibull_min :  4.5434056023072635\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  4.943153732081112\n",
      "dweibull  distribution parameters:  (1, 0, 6.2608527615589225)\n",
      "SSE for  dweibull :  8.569029790366212\n",
      "expon  distribution parameters:  (1.0, 5.260869565217392)\n",
      "SSE for  expon :  8.213223721896101\n",
      "gamma  distribution parameters:  (1.239460845934661, 0, 5.0512846660324735)\n",
      "SSE for  gamma :  8.346206441743336\n",
      "invweibull  distribution parameters:  (1, 0, 2.4725585937500036)\n",
      "SSE for  invweibull :  8.205907386439193\n",
      "lognorm  distribution parameters:  (1.0070292820705924, 0.0, 3.9728985623681807)\n",
      "SSE for  lognorm :  8.309511407020723\n",
      "norm  distribution parameters:  (6.260869565217392, 5.914002479777368)\n",
      "SSE for  norm :  8.594149824890495\n",
      "weibull_min  distribution parameters:  (1, 0, 6.26088702464224)\n",
      "SSE for  weibull_min :  8.296336241829975\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  9.073724007561438\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for SAV before APREQ-prescheduling\n",
      "D'sub.05 for  SAV  delay dataset w/ sample size of 7  =  0.514031683292549\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9340228345530174 p =  1.0883925687715683e-08\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9830288290977478 p =  0.972922682762146\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for SAV after APREQ-prescheduling\n",
      "D'sub.05 for  SAV  delay dataset w/ sample size of 23  =  0.2835796031176217\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9495973285927363 p =  2.8672249420228828e-30\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9273013472557068 p =  0.09563430398702621\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  SAV ***\n",
      "\n",
      "Sample sizes - Before: 14 ; After: 46\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 14 46  =  0.4151180330538046\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.21739130434782608 p =  0.6100322937821389\n",
      "2 sample KS test results for normalized data : D =  0.15527950310559005 p =  0.9147606879134482\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  -8.957186111694346e-16 p =  0.9999999999999993\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "0.537455833770682\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(0.2080745341614907, 'small')\n",
      "\n",
      "\n",
      "\n",
      "Airport:  CAE\n",
      "Identified outliers using Z method for delay data for: CAE\n",
      "Number of outliers: 3\n",
      "No-outlier observations for dataset: 184\n",
      "Identified outliers using Z method for delay data for: CAE\n",
      "Number of outliers: 2\n",
      "No-outlier observations for dataset: 151\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n",
      "dweibull  distribution parameters:  (1, 0, 10.130411177901713)\n",
      "SSE for  dweibull :  2.0836890521875624\n",
      "expon  distribution parameters:  (1.0, 9.130434782608695)\n",
      "SSE for  expon :  2.0017484783121797\n",
      "gamma  distribution parameters:  (2.0089853917644227, 0, 5.04256269066819)\n",
      "SSE for  gamma :  1.9894527875164547\n",
      "invweibull  distribution parameters:  (1, 0, 5.43916015625001)\n",
      "SSE for  invweibull :  2.0163831836506985\n",
      "lognorm  distribution parameters:  (0.7933317671135869, 0.0, 7.740586729228079)\n",
      "SSE for  lognorm :  1.9971100314610108\n",
      "norm  distribution parameters:  (10.130434782608695, 6.917553901841107)\n",
      "SSE for  norm :  2.029768750933023\n",
      "weibull_min  distribution parameters:  (1, 0, 10.13046875000002)\n",
      "SSE for  weibull_min :  1.9962972124079152\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  2.3014778635203923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dweibull  distribution parameters:  (1, 0, 9.466650546494492)\n",
      "SSE for  dweibull :  3.203876281303342\n",
      "expon  distribution parameters:  (1.0, 8.466666666666667)\n",
      "SSE for  expon :  3.080526737646565\n",
      "gamma  distribution parameters:  (1.6628321571033637, 0, 5.693098143565795)\n",
      "SSE for  gamma :  3.112531658299777\n",
      "invweibull  distribution parameters:  (1, 0, 4.485546875000008)\n",
      "SSE for  invweibull :  3.1089584041885523\n",
      "lognorm  distribution parameters:  (0.886048254780868, 0.0, 6.806613303370268)\n",
      "SSE for  lognorm :  3.112267434942389\n",
      "norm  distribution parameters:  (9.466666666666667, 6.829999186595039)\n",
      "SSE for  norm :  3.1883975901154713\n",
      "weibull_min  distribution parameters:  (1, 0, 9.46669921875002)\n",
      "SSE for  weibull_min :  3.083188054270517\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  3.4823959762231222\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for CAE before APREQ-prescheduling\n",
      "D'sub.05 for  CAE  delay dataset w/ sample size of 92  =  0.14178980155881085\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9894005020591738 p =  4.2391337497370774e-182\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9809417724609375 p =  0.1982697695493698\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for CAE after APREQ-prescheduling\n",
      "D'sub.05 for  CAE  delay dataset w/ sample size of 76  =  0.156002699031982\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9818828970278691 p =  8.2371164055307e-133\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9751604199409485 p =  0.14142809808254242\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  CAE ***\n",
      "\n",
      "Sample sizes - Before: 184 ; After: 151\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 184 151  =  0.14933579790378473\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.13342211344658797 p =  0.09278839378910408\n",
      "2 sample KS test results for normalized data : D =  0.07907428735963144 p =  0.6388528123937505\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  -2.139345438010506e-15 p =  0.9999999999999982\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "0.21257549274842596\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(0.12798733083789232, 'negligible')\n",
      "\n",
      "\n",
      "\n",
      "Airport:  AVL\n",
      "Identified outliers using Z method for delay data for: AVL\n",
      "Number of outliers: 2\n",
      "No-outlier observations for dataset: 119\n",
      "Identified outliers using Z method for delay data for: AVL\n",
      "Number of outliers: 2\n",
      "No-outlier observations for dataset: 220\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n",
      "dweibull  distribution parameters:  (1, 0, 11.593236282479378)\n",
      "SSE for  dweibull :  2.068888201064058\n",
      "expon  distribution parameters:  (2.0, 9.59322033898305)\n",
      "SSE for  expon :  1.9786853515111036\n",
      "gamma  distribution parameters:  (2.353769258960436, 0, 4.925385228330879)\n",
      "SSE for  gamma :  1.9697012051896432\n",
      "invweibull  distribution parameters:  (1, 0, 7.285546875000014)\n",
      "SSE for  invweibull :  1.9805293650233995\n",
      "lognorm  distribution parameters:  (0.6891412671175492, 0.0, 9.236890643707579)\n",
      "SSE for  lognorm :  1.9668234028102491\n",
      "norm  distribution parameters:  (11.59322033898305, 7.957767006586191)\n",
      "SSE for  norm :  2.0149858454253335\n",
      "weibull_min  distribution parameters:  (1, 0, 11.593261718750027)\n",
      "SSE for  weibull_min :  1.9829245517061982\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  2.2419079668638453\n",
      "dweibull  distribution parameters:  (1, 0, 15.254561029005204)\n",
      "SSE for  dweibull :  0.583811295761196\n",
      "expon  distribution parameters:  (1.0, 14.254545454545454)\n",
      "SSE for  expon :  0.5484586652138942\n",
      "gamma  distribution parameters:  (1.4818394593793194, 0, 10.29433071038272)\n",
      "SSE for  gamma :  0.5488792444489266\n",
      "invweibull  distribution parameters:  (1, 0, 6.297753906250012)\n",
      "SSE for  invweibull :  0.5702480102952938\n",
      "lognorm  distribution parameters:  (0.9475733579347243, 0.0, 10.495731960732241)\n",
      "SSE for  lognorm :  0.5506777457073482\n",
      "norm  distribution parameters:  (15.254545454545454, 12.24406079670419)\n",
      "SSE for  norm :  0.5791320770799244\n",
      "weibull_min  distribution parameters:  (1, 0, 15.25458984375003)\n",
      "SSE for  weibull_min :  0.5480124895992711\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  0.6770247933884297\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for AVL before APREQ-prescheduling\n",
      "D'sub.05 for  AVL  delay dataset w/ sample size of 60  =  0.17557524502806957\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.985057124257281 p =  5.84899299850409e-110\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9827244281768799 p =  0.5539070963859558\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for AVL after APREQ-prescheduling\n",
      "D'sub.05 for  AVL  delay dataset w/ sample size of 110  =  0.12967091213740056\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9903730511095551 p =  3.053396981716926e-222\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.977070152759552 p =  0.054660893976688385\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  AVL ***\n",
      "\n",
      "Sample sizes - Before: 119 ; After: 220\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 119 220  =  0.1547582949961968\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.1027501909854851 p =  0.35732260972848073\n",
      "2 sample KS test results for normalized data : D =  0.10003819709702062 p =  0.3896503979171787\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  -7.222845145643208e-16 p =  0.9999999999999994\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "-0.13149119752348423\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(-0.013025210084033614, 'negligible')\n",
      "\n",
      "\n",
      "\n",
      "Airport:  GSP\n",
      "Identified outliers using Z method for delay data for: GSP\n",
      "Number of outliers: 3\n",
      "No-outlier observations for dataset: 405\n",
      "Identified outliers using Z method for delay data for: GSP\n",
      "Number of outliers: 5\n",
      "No-outlier observations for dataset: 472\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dweibull  distribution parameters:  (1, 0, 14.569328663909591)\n",
      "SSE for  dweibull :  0.6068936778674443\n",
      "expon  distribution parameters:  (1.0, 13.569306930693068)\n",
      "SSE for  expon :  0.5681273075560853\n",
      "gamma  distribution parameters:  (1.5798252891665236, 0, 9.222100083218361)\n",
      "SSE for  gamma :  0.571132022838132\n",
      "invweibull  distribution parameters:  (1, 0, 6.339648437500011)\n",
      "SSE for  invweibull :  0.5870016492719763\n",
      "lognorm  distribution parameters:  (0.9239658364444332, 0.0, 10.27986268399382)\n",
      "SSE for  lognorm :  0.5747430488070814\n",
      "norm  distribution parameters:  (14.569306930693068, 10.854467005574271)\n",
      "SSE for  norm :  0.5984335325587998\n",
      "weibull_min  distribution parameters:  (1, 0, 14.569335937500028)\n",
      "SSE for  weibull_min :  0.5671082775475977\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  0.7115948638416962\n",
      "dweibull  distribution parameters:  (1, 0, 16.618654208917533)\n",
      "SSE for  dweibull :  0.4113265082660056\n",
      "expon  distribution parameters:  (1.0, 15.618644067796609)\n",
      "SSE for  expon :  0.38318945424024686\n",
      "gamma  distribution parameters:  (1.5583624643760963, 0, 10.664171171788347)\n",
      "SSE for  gamma :  0.3847550370288105\n",
      "invweibull  distribution parameters:  (1, 0, 6.920312500000014)\n",
      "SSE for  invweibull :  0.4036607142881432\n",
      "lognorm  distribution parameters:  (0.9473584687892926, 0.0, 11.664738890345422)\n",
      "SSE for  lognorm :  0.3904663581419743\n",
      "norm  distribution parameters:  (16.61864406779661, 12.132334923823226)\n",
      "SSE for  norm :  0.4009575494827333\n",
      "weibull_min  distribution parameters:  (1, 0, 16.618652343750036)\n",
      "SSE for  weibull_min :  0.3817606223193211\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  0.4941108876759552\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for GSP before APREQ-prescheduling\n",
      "D'sub.05 for  GSP  delay dataset w/ sample size of 203  =  0.09545328726272913\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.984397814448915 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9741662740707397 p =  0.0008554402738809586\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for GSP after APREQ-prescheduling\n",
      "D'sub.05 for  GSP  delay dataset w/ sample size of 236  =  0.08852845946696024\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9816133584238456 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9813990592956543 p =  0.003430189797654748\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  GSP ***\n",
      "\n",
      "Sample sizes - Before: 405 ; After: 472\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 405 472  =  0.09211708662372864\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.08664992676292112 p =  0.07016444649144127\n",
      "2 sample KS test results for normalized data : D =  0.057020297133291487 p =  0.455524207332751\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  6.4905077476572435e-15 p =  0.9999999999999949\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "-0.16235514618683464\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(-0.07468089558485039, 'negligible')\n",
      "\n",
      "\n",
      "\n",
      "Airport:  CLT\n",
      "Identified outliers using Z method for delay data for: CLT\n",
      "Number of outliers: 9\n",
      "No-outlier observations for dataset: 562\n",
      "Identified outliers using Z method for delay data for: CLT\n",
      "Number of outliers: 13\n",
      "No-outlier observations for dataset: 618\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n",
      "dweibull  distribution parameters:  (1, 0, 11.64410591569543)\n",
      "SSE for  dweibull :  0.9087443119311799\n",
      "expon  distribution parameters:  (1.0, 10.644128113879004)\n",
      "SSE for  expon :  0.8454499250937683\n",
      "gamma  distribution parameters:  (1.5168706952953313, 0, 7.676414443231049)\n",
      "SSE for  gamma :  0.8569920937426392\n",
      "invweibull  distribution parameters:  (1, 0, 4.949218750000008)\n",
      "SSE for  invweibull :  0.8889850311940973\n",
      "lognorm  distribution parameters:  (0.9405202008559207, 0.0, 8.0873125006888)\n",
      "SSE for  lognorm :  0.86768022278859\n",
      "norm  distribution parameters:  (11.644128113879004, 9.070779963754308)\n",
      "SSE for  norm :  0.8988008511107168\n",
      "weibull_min  distribution parameters:  (1, 0, 11.644140625000025)\n",
      "SSE for  weibull_min :  0.8463445452846706\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  1.0592658409270037\n",
      "dweibull  distribution parameters:  (1, 0, 10.55666069998168)\n",
      "SSE for  dweibull :  1.099679677512976\n",
      "expon  distribution parameters:  (1.0, 9.556634304207119)\n",
      "SSE for  expon :  1.0248333749356224\n",
      "gamma  distribution parameters:  (1.6079492360592458, 0, 6.565278348015058)\n",
      "SSE for  gamma :  1.0310332192801095\n",
      "invweibull  distribution parameters:  (1, 0, 4.881835937500009)\n",
      "SSE for  invweibull :  1.0536596780853027\n",
      "lognorm  distribution parameters:  (0.8907581410635128, 0.0, 7.4980583416872175)\n",
      "SSE for  lognorm :  1.037570065862467\n",
      "norm  distribution parameters:  (10.556634304207119, 8.369357520526652)\n",
      "SSE for  norm :  1.0795755965875782\n",
      "weibull_min  distribution parameters:  (1, 0, 10.556640625000021)\n",
      "SSE for  weibull_min :  1.0259049243372114\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  1.273871306813827\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for CLT before APREQ-prescheduling\n",
      "D'sub.05 for  CLT  delay dataset w/ sample size of 281  =  0.08113079813297754\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9687185041541605 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9657458066940308 p =  3.162002940371167e-06\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for CLT after APREQ-prescheduling\n",
      "D'sub.05 for  CLT  delay dataset w/ sample size of 309  =  0.0773676968624461\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9877261003573796 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9804267883300781 p =  0.0003151650307700038\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  CLT ***\n",
      "\n",
      "Sample sizes - Before: 562 ; After: 618\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 562 618  =  0.0792715804166074\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.08504071220444782 p =  0.026204672199608536\n",
      "2 sample KS test results for normalized data : D =  0.061672943371454236 p =  0.2015678952409179\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  6.7563785112163184e-15 p =  0.9999999999999947\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "0.12560593681679721\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(0.029042716143224036, 'negligible')\n",
      "\n",
      "\n",
      "\n",
      "Airport:  RDU\n",
      "Identified outliers using Z method for delay data for: RDU\n",
      "Number of outliers: 4\n",
      "No-outlier observations for dataset: 368\n",
      "Identified outliers using Z method for delay data for: RDU\n",
      "Number of outliers: 8\n",
      "No-outlier observations for dataset: 832\n",
      "\n",
      "\n",
      "***Find best fit pdf for ORDDOOGE delay by airport dataset***\n",
      "dweibull  distribution parameters:  (1, 0, 11.652204301023495)\n",
      "SSE for  dweibull :  1.0851943734014098\n",
      "expon  distribution parameters:  (1.0, 10.652173913043478)\n",
      "SSE for  expon :  1.0149127777816112\n",
      "gamma  distribution parameters:  (1.45784987225644, 0, 7.9927118249895)\n",
      "SSE for  gamma :  1.023910263038399\n",
      "invweibull  distribution parameters:  (1, 0, 4.8545898437500075)\n",
      "SSE for  invweibull :  1.063666918217066\n",
      "lognorm  distribution parameters:  (0.9491738737307845, 0.0, 7.963461413159089)\n",
      "SSE for  lognorm :  1.0331290843541654\n",
      "norm  distribution parameters:  (11.652173913043478, 9.653153103484865)\n",
      "SSE for  norm :  1.0776101900615487\n",
      "weibull_min  distribution parameters:  (1, 0, 11.652148437500024)\n",
      "SSE for  weibull_min :  1.0169960462075762\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  1.2459467890615221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dweibull  distribution parameters:  (1, 0, 13.36541037992686)\n",
      "SSE for  dweibull :  0.7099537352600158\n",
      "expon  distribution parameters:  (1.0, 12.365384615384615)\n",
      "SSE for  expon :  0.6664823534847034\n",
      "gamma  distribution parameters:  (1.7238700591900789, 0, 7.753127646792611)\n",
      "SSE for  gamma :  0.6656016072547731\n",
      "invweibull  distribution parameters:  (1, 0, 6.219335937500011)\n",
      "SSE for  invweibull :  0.6886644718309717\n",
      "lognorm  distribution parameters:  (0.8794341931019228, 0.0, 9.731894757959441)\n",
      "SSE for  lognorm :  0.672288962851304\n",
      "norm  distribution parameters:  (13.365384615384615, 9.643957546555425)\n",
      "SSE for  norm :  0.6898117424259818\n",
      "weibull_min  distribution parameters:  (1, 0, 13.365429687500026)\n",
      "SSE for  weibull_min :  0.6643920608742916\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  0.8303004822693238\n",
      "\n",
      "***Test data distributions for normality:***\n",
      "Test for normality using KS: normalized delay distribution for RDU before APREQ-prescheduling\n",
      "D'sub.05 for  RDU  delay dataset w/ sample size of 184  =  0.10026053018533006\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9812031321122534 p =  5.404554e-318\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9805184006690979 p =  0.011349712498486042\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "Test for normality using KS: normalized delay distribution for RDU after APREQ-prescheduling\n",
      "D'sub.05 for  RDU  delay dataset w/ sample size of 416  =  0.06667948594698259\n",
      "Find D'sub.05 critical value from the table below if sample size < 35\n",
      "KS test results against normal dist: D =  0.9836699548074365 p =  0.0\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\n",
      "Shapiro-Wilk test results against normal dist: W =  0.9846068024635315 p =  0.00021095732518006116\n",
      "The null hypothesis is rejected if p < alpha=.05\n",
      "\n",
      "***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport  RDU ***\n",
      "\n",
      "Sample sizes - Before: 368 ; After: 832\n",
      "Use KS test if normalized data distributions do not pass test for normality:\n",
      "D'sub.05 for dataset w/ sample sizes of 368 832  =  0.08514202182000769\n",
      "2 sample KS test results for raw data w/o outliers : D =  0.16048285953177258 p =  3.2838031719384375e-06\n",
      "2 sample KS test results for normalized data : D =  0.08136496655518395 p =  0.06382650426264391\n",
      "The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\n",
      "\n",
      "Use Welch's T-test if normalized data distributions pass test for normality:\n",
      "2 sample Welch's T-test results for normalized data : T =  1.777319194646132e-15 p =  0.9999999999999986\n",
      "The null hypothesis is rejected if T > 1.96, p < alpha=.05\n",
      "If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\n",
      "https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\n",
      "\n",
      "***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\n",
      "Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\n",
      "-0.2611463076971708\n",
      "\n",
      "If data distributions do not pass normality test, compute effect size using Cliff's Delta:\n",
      "(-0.17448134406354515, 'small')\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "#Remove outliers for airports to streamclass ORD_DOOGE        #\n",
    "#then find best fit pdf for ORDDOOGE delay by airport dataset #\n",
    "#before and after APREQ prescheduling                         #\n",
    "#Also run statistical tests to compare delay distributions    #\n",
    "#between pre and post APREQ prescheduling                     #\n",
    "###############################################################\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_PDF_PP_plots_byAirports.pdf\")\n",
    "\n",
    "origAptList = [\n",
    "    'CHS',\n",
    "    'SAV',\n",
    "    'CAE',\n",
    "    'AVL',\n",
    "    'GSP',\n",
    "    'CLT',\n",
    "    'RDU']\n",
    "\n",
    "for aptName in origAptList:\n",
    "    matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "    matplotlib.style.use('ggplot')\n",
    "    \n",
    "    subset_byAirport_ORDDOOGE_preAPREQ = subset_ORDDOOGE_preAPREQ[subset_ORDDOOGE_preAPREQ['origApt']==aptName]\n",
    "    subset_byAirport_ORDDOOGE_pstAPREQ = subset_ORDDOOGE_pstAPREQ[subset_ORDDOOGE_pstAPREQ['origApt']==aptName]\n",
    "    print('Airport: ', aptName)\n",
    "    \n",
    "    #######################\n",
    "    #identify outliers using Z for preAPREQ set\n",
    "    print(\"Identified outliers using Z method for delay data for:\", aptName)\n",
    "    subset_DelayByAirport_ORDDOOGE_preAPREQ_noO = pd.DataFrame(outliers_Z(subset_byAirport_ORDDOOGE_preAPREQ['FinalDelay']))\n",
    "\n",
    "    #######################\n",
    "    #identify outliers using Z for pstAPREQ set\n",
    "    print(\"Identified outliers using Z method for delay data for:\", aptName)\n",
    "    subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO = pd.DataFrame(outliers_Z(subset_byAirport_ORDDOOGE_pstAPREQ['FinalDelay']))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    #######################\n",
    "    #Perform evaluation of best fit distribution for pre-APREQ by\n",
    "    #iterating through a list of dist and evaluate fit by computing the sum squared error\n",
    "    X_train_DelayByAirport_ORDDOOGE_preAPREQ, X_test_DelayByAirport_ORDDOOGE_preAPREQ = train_test_split(subset_DelayByAirport_ORDDOOGE_preAPREQ_noO,test_size=.5)\n",
    "    X_train_DelayByAirport_ORDDOOGE_preAPREQ = X_train_DelayByAirport_ORDDOOGE_preAPREQ.astype(int)\n",
    "    X_test_DelayByAirport_ORDDOOGE_preAPREQ = X_test_DelayByAirport_ORDDOOGE_preAPREQ.astype(int)\n",
    "\n",
    "    X_train_DelayByAirport_ORDDOOGE_pstAPREQ, X_test_DelayByAirport_ORDDOOGE_pstAPREQ = train_test_split(subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO,test_size=.5)\n",
    "    X_train_DelayByAirport_ORDDOOGE_pstAPREQ = X_train_DelayByAirport_ORDDOOGE_pstAPREQ.astype(int)\n",
    "    X_test_DelayByAirport_ORDDOOGE_pstAPREQ = X_test_DelayByAirport_ORDDOOGE_pstAPREQ.astype(int)\n",
    "\n",
    "    ###################################\n",
    "    # Create models from data\n",
    "    ###################################\n",
    "\n",
    "    print(\"***Find best fit pdf for ORDDOOGE delay by airport dataset***\")\n",
    "    ############################################################\n",
    "    # Find best fit pdf for ORDDOOGE delay dataset\n",
    "\n",
    "    # use half of dataset (randomly drawn) to find distribution params utilizing fit function\n",
    "    #data = subset_Delay_ORDDOOGE_noO #if use full dataset\n",
    "    \n",
    "    #Pre APREQ Prescheduling\n",
    "    data_DelayByAirport_preAPREQ = X_train_DelayByAirport_ORDDOOGE_preAPREQ\n",
    "    \n",
    "    # Plot for comparison\n",
    "    plt.figure()\n",
    "    ax1 = data_DelayByAirport_preAPREQ.plot(kind='hist', bins=50, density=True, alpha=0.5, legend=False)\n",
    "\n",
    "    # Save plot limits\n",
    "    dataYLim1 = ax1.get_ylim()\n",
    "\n",
    "    # Find best fit distribution\n",
    "    best_fit_DelayByAirport_preAPREQ_name, best_fit_DelayByAirport_preAPREQ_params = best_fit_distribution(data_DelayByAirport_preAPREQ, 200, ax1)\n",
    "    best_DelayByAirport_preAPREQ_dist = getattr(st, best_fit_DelayByAirport_preAPREQ_name)\n",
    "\n",
    "    # Update plots\n",
    "    ax1.set_ylim(dataYLim1)\n",
    "    ax1.set_title(u'Delays at ' + aptName + ' to ORD_DOOGE before APREQ Prescheduling\\n Selected Fitted Distributions')\n",
    "    ax1.set_xlabel('Minutes')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    pdf.savefig()\n",
    "\n",
    "    #Post APREQ Prescheduling\n",
    "    data_DelayByAirport_pstAPREQ = X_train_DelayByAirport_ORDDOOGE_pstAPREQ\n",
    "    plt.figure()\n",
    "    ax2 = data_DelayByAirport_pstAPREQ.plot(kind='hist', bins=50, density=True, alpha=0.5, legend=False)\n",
    "    dataYLim2 = ax2.get_ylim()\n",
    "    best_fit_DelayByAirport_pstAPREQ_name, best_fit_DelayByAirport_pstAPREQ_params = best_fit_distribution(data_DelayByAirport_pstAPREQ, 200, ax2)\n",
    "    best_DelayByAirport_pstAPREQ_dist = getattr(st, best_fit_DelayByAirport_pstAPREQ_name)\n",
    "    ax2.set_ylim(dataYLim2)\n",
    "    ax2.set_title(u'Delays at ' + aptName + ' to ORD_DOOGE after APREQ Prescheduling\\n Selected Fitted Distributions')\n",
    "    ax2.set_xlabel('Minutes')\n",
    "    ax2.set_ylabel('Frequency')    \n",
    "    pdf.savefig()\n",
    "    \n",
    "    #######################    \n",
    "    # Make PDF with best params \n",
    "    pdf_DelayByAirport_preAPREQ = make_pdf(best_DelayByAirport_preAPREQ_dist, best_fit_DelayByAirport_preAPREQ_params)\n",
    "    pdf_DelayByAirport_pstAPREQ = make_pdf(best_DelayByAirport_pstAPREQ_dist, best_fit_DelayByAirport_pstAPREQ_params)\n",
    "\n",
    "    ##############################################    \n",
    "    # Display\n",
    "    \n",
    "    #pre-APREQ prescheduling \n",
    "    plt.figure()\n",
    "    ax = pdf_DelayByAirport_preAPREQ.plot(lw=2, label='pdf', legend=True)\n",
    "    data_DelayByAirport_preAPREQ.plot(kind='hist', bins=50, density=True, label='Data', legend=False, alpha=0.5, ax=ax)\n",
    "\n",
    "    param_DelayByAirport_preAPREQ_names = (best_DelayByAirport_preAPREQ_dist.shapes + ', loc, scale').split(', ') if best_DelayByAirport_preAPREQ_dist.shapes else ['loc', 'scale']\n",
    "    param_DelayByAirport_preAPREQ_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_DelayByAirport_preAPREQ_names, best_fit_DelayByAirport_preAPREQ_params)])\n",
    "    dist_DelayByAirport_preAPREQ_str = '{}({})'.format(best_fit_DelayByAirport_preAPREQ_name, param_DelayByAirport_preAPREQ_str)\n",
    "\n",
    "    ax.set_title(u'Delays at ' + aptName + ' to ORD_DOOGE before APREQ prescheduling with best fit distribution \\n' + dist_DelayByAirport_preAPREQ_str)\n",
    "    ax.set_xlabel('Minutes')\n",
    "    ax.set_ylabel('Frequency')   \n",
    "    pdf.savefig()\n",
    "\n",
    "    #post APREQ prescheduling\n",
    "    plt.figure()\n",
    "    ax = pdf_DelayByAirport_pstAPREQ.plot(lw=2, label='pdf', legend=True)\n",
    "    data_DelayByAirport_pstAPREQ.plot(kind='hist', bins=50, density=True, label='Data', legend=False, alpha=0.5, ax=ax)\n",
    "\n",
    "    param_DelayByAirport_pstAPREQ_names = (best_DelayByAirport_pstAPREQ_dist.shapes + ', loc, scale').split(', ') if best_DelayByAirport_pstAPREQ_dist.shapes else ['loc', 'scale']\n",
    "    param_DelayByAirport_pstAPREQ_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_DelayByAirport_pstAPREQ_names, best_fit_DelayByAirport_pstAPREQ_params)])\n",
    "    dist_DelayByAirport_pstAPREQ_str = '{}({})'.format(best_fit_DelayByAirport_pstAPREQ_name, param_DelayByAirport_pstAPREQ_str)\n",
    "\n",
    "    ax.set_title(u'Delays at ' + aptName + ' to ORD_DOOGE after APREQ Prescheduling with best fit distribution \\n' + dist_DelayByAirport_pstAPREQ_str)\n",
    "    ax.set_xlabel('Minutes')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    pdf.savefig()\n",
    "\n",
    "    #################################################################################################\n",
    "    #Run statistical tests to compare delay distributions between pre and post APREQ prescheduling  #\n",
    "    #################################################################################################\n",
    "    \n",
    "    #For each airport, run KS test against a normal dist on the test dataset using params derived from train dataset\n",
    "    X_train_DelayByAirport_ORDDOOGE_preAPREQ_xformed = xform(X_train_DelayByAirport_ORDDOOGE_preAPREQ)\n",
    "    X_test_DelayByAirport_ORDDOOGE_preAPREQ_xformed = xform(X_test_DelayByAirport_ORDDOOGE_preAPREQ)\n",
    "\n",
    "    s = pd.DataFrame(X_train_DelayByAirport_ORDDOOGE_preAPREQ_xformed).describe(include='all')\n",
    "    X_train_DelayByAirport_ORDDOOGE_preAPREQ_fit_params = [s.loc['mean'], s.loc['std']]\n",
    "\n",
    "    print(\"\\n***Test data distributions for normality:***\")\n",
    "    statTest, pTest = st.kstest(X_test_DelayByAirport_ORDDOOGE_preAPREQ_xformed, 'norm', args=(X_train_DelayByAirport_ORDDOOGE_preAPREQ_fit_params))\n",
    "    sizeX_test = len(X_test_DelayByAirport_ORDDOOGE_preAPREQ_xformed)\n",
    "    print(\"Test for normality using KS: normalized delay distribution for\", aptName, \"before APREQ-prescheduling\")\n",
    "    print(\"D'sub.05 for \", aptName, \" delay dataset w/ sample size of\", sizeX_test, \" = \", 1.36/np.sqrt(sizeX_test))\n",
    "    print(\"Find D'sub.05 critical value from the table below if sample size < 35\")\n",
    "    print(\"KS test results against normal dist: D = \", statTest, \"p = \", pTest)\n",
    "    print(\"The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\\n\")\n",
    "\n",
    "    #Try testing against normality using shapiro-wilk; we'll see that it works better for large sample sizes\n",
    "    #It looks like since critical value for W is harder to compute, evaluate p-value only\n",
    "    statTest, pTest = st.shapiro(X_test_DelayByAirport_ORDDOOGE_preAPREQ_xformed)\n",
    "    print(\"Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\")\n",
    "    print(\"Shapiro-Wilk test results against normal dist: W = \", statTest, \"p = \", pTest)\n",
    "    print(\"The null hypothesis is rejected if p < alpha=.05\")\n",
    "\n",
    "    X_train_DelayByAirport_ORDDOOGE_pstAPREQ_xformed = xform(X_train_DelayByAirport_ORDDOOGE_pstAPREQ)\n",
    "    X_test_DelayByAirport_ORDDOOGE_pstAPREQ_xformed = xform(X_test_DelayByAirport_ORDDOOGE_pstAPREQ)\n",
    "        \n",
    "    s = pd.DataFrame(X_train_DelayByAirport_ORDDOOGE_pstAPREQ_xformed).describe(include='all')\n",
    "    X_train_DelayByAirport_ORDDOOGE_pstAPREQ_fit_params = [s.loc['mean'], s.loc['std']]\n",
    "   \n",
    "    statTest, pTest = st.kstest(X_test_DelayByAirport_ORDDOOGE_pstAPREQ_xformed, 'norm', args=(X_train_DelayByAirport_ORDDOOGE_pstAPREQ_fit_params))\n",
    "    sizeX_test = len(X_test_DelayByAirport_ORDDOOGE_pstAPREQ_xformed)\n",
    "    print(\"\\nTest for normality using KS: normalized delay distribution for\", aptName, \"after APREQ-prescheduling\")\n",
    "    print (\"D'sub.05 for \", aptName, \" delay dataset w/ sample size of\", sizeX_test, \" = \", 1.36/np.sqrt(sizeX_test))\n",
    "    print(\"Find D'sub.05 critical value from the table below if sample size < 35\")\n",
    "    print(\"KS test results against normal dist: D = \", statTest, \"p = \", pTest)\n",
    "    print(\"The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\\n\")\n",
    "\n",
    "    #Try testing against normality using shapiro-wilk; we'll see that it works better for large sample sizes\n",
    "    #It looks like since critical value for W is harder to compute, evaluate p-value only\n",
    "    statTest, pTest = st.shapiro(X_test_DelayByAirport_ORDDOOGE_pstAPREQ_xformed)\n",
    "    print(\"Test for normality using Shapiro-Wilk: normalized delay distribution for ORD_DOOGE before APREQ-prescheduling\")\n",
    "    print(\"Shapiro-Wilk test results against normal dist: W = \", statTest, \"p = \", pTest)\n",
    "    print(\"The null hypothesis is rejected if p < alpha=.05\")    \n",
    "    \n",
    "    #P-P plots and histograms for normality assessment\n",
    "    left = -1.8   #x coordinate for text insert\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = fig.add_subplot(221)\n",
    "    prob= st.probplot(X_test_DelayByAirport_ORDDOOGE_preAPREQ_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "    ax.set_title('PP Plot: Delays data before APREQ presscheduling against a normal dist for ' + aptName)\n",
    "    top = ax.get_ylim()[1] * 0.75\n",
    "    txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "    txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "    ax = fig.add_subplot(222)\n",
    "    prob = plt.hist(X_test_DelayByAirport_ORDDOOGE_preAPREQ_xformed)\n",
    "    ax.set_title('Histogram of normalized delays data for ' + aptName)\n",
    "\n",
    "    ax = fig.add_subplot(223)\n",
    "    prob = st.probplot(X_test_DelayByAirport_ORDDOOGE_pstAPREQ_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "    ax.set_title('PP Plot: Delays data after APREQ presscheduling against a normal dist for ' + aptName)\n",
    "    top = ax.get_ylim()[1] * 0.75\n",
    "    txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "    txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "    ax = fig.add_subplot(224)\n",
    "    prob = plt.hist(X_test_DelayByAirport_ORDDOOGE_pstAPREQ_xformed)\n",
    "    ax.set_title('Histogram of normalized delays data for ' + aptName)    \n",
    "    pdf.savefig()    \n",
    "      \n",
    "    ##################################################################################\n",
    "    #Then compare the delay distribution before vs. after APREQ pre-scheduling to\n",
    "    #assess for statistically significant differences between the two.\n",
    "    #If there is a statistically significant difference, then assess the effect size\n",
    "    #A small p (â‰¤ alpha = .05), reject the null hypothesis.\n",
    "    #A large p (> alpha = .05) accept the null hypothesis\n",
    "\n",
    "    print(\"\\n***Assess if there is a statistically significant difference between before vs. after APREQ-prescheduling delay distribution for airport \", aptName, \"***\\n\")\n",
    "\n",
    "    #1st try to normalize the dataset for pre & post APREQ prescheduling \n",
    "    subset_DelayByAirport_ORDDOOGE_preAPREQ_xformed = xform(subset_DelayByAirport_ORDDOOGE_preAPREQ_noO)\n",
    "    subset_DelayByAirport_ORDDOOGE_pstAPREQ_xformed = xform(subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO)    \n",
    "    \n",
    "    sizeX_2samp_test = len(subset_DelayByAirport_ORDDOOGE_preAPREQ_noO)\n",
    "    sizeY_2samp_test = len(subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO)\n",
    "    \n",
    "    print(\"Sample sizes - Before:\", sizeX_2samp_test, \"; After:\", sizeY_2samp_test)\n",
    "    statTest_delay_2samp_ks, pTest_delay_2samp_ks = st.ks_2samp(subset_DelayByAirport_ORDDOOGE_preAPREQ_noO.iloc[:,0], subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO.iloc[:,0])\n",
    "    statTest_delay_2samp_norm_ks, pTest_delay_2samp_norm_ks = st.ks_2samp(subset_DelayByAirport_ORDDOOGE_preAPREQ_xformed.flatten(), subset_DelayByAirport_ORDDOOGE_pstAPREQ_xformed.flatten())\n",
    "    statTest_delay_2samp_norm_t, pTest_delay_2samp_norm_t = st.ttest_ind(subset_DelayByAirport_ORDDOOGE_preAPREQ_xformed.flatten(), subset_DelayByAirport_ORDDOOGE_pstAPREQ_xformed.flatten(), equal_var=False)\n",
    "\n",
    "\n",
    "    print(\"Use KS test if normalized data distributions do not pass test for normality:\")\n",
    "    print (\"D'sub.05 for dataset w/ sample sizes of\", sizeX_2samp_test, sizeY_2samp_test, \" = \", 1.36*np.sqrt((sizeX_2samp_test + sizeY_2samp_test)/(sizeX_2samp_test*sizeY_2samp_test)))\n",
    "    print(\"2 sample KS test results for raw data w/o outliers : D = \", statTest_delay_2samp_ks, \"p = \", pTest_delay_2samp_ks)\n",
    "    print(\"2 sample KS test results for normalized data : D = \", statTest_delay_2samp_norm_ks, \"p = \", pTest_delay_2samp_norm_ks)\n",
    "    print(\"The null hypothesis is rejected if D > D'sub.05, p < alpha=.05\")\n",
    "\n",
    "    print(\"\\nUse Welch's T-test if normalized data distributions pass test for normality:\")\n",
    "    print(\"2 sample Welch's T-test results for normalized data : T = \", statTest_delay_2samp_norm_t, \"p = \", pTest_delay_2samp_norm_t)\n",
    "    print(\"The null hypothesis is rejected if T > 1.96, p < alpha=.05\")\n",
    "    print(\"If (sum of 2 sample sizes - 2) < 100, critical value of T can be found at:\")\n",
    "    print(\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda3672.htm\")\n",
    "    \n",
    "    #compute the Cohen's D coefficient since sample sizes are different, can use Pearson if the sample sizes are the same\n",
    "    print(\"\\n***If a significant difference is found (i.e. p < alpha=.05; reject the null hypothesis), then assess the effect size:***\")\n",
    "    print(\"Compute effect size using Cohen's D Coefficient: Small: d=0.20; Medium: d=0.50; Large: d=0.80\")\n",
    "    print(cohend(subset_DelayByAirport_ORDDOOGE_preAPREQ_noO.iloc[:,0], subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO.iloc[:,0]))\n",
    "\n",
    "    #compute the Cliff's Delta coefficient if non-parametric distribution\n",
    "    print(\"\\nIf data distributions do not pass normality test, compute effect size using Cliff's Delta:\")\n",
    "    print(cliffsDelta(subset_DelayByAirport_ORDDOOGE_preAPREQ_noO.iloc[:,0], subset_DelayByAirport_ORDDOOGE_pstAPREQ_noO.iloc[:,0]))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    plt.close('all')\n",
    "    \n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"KS_Critical_Values.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOME ADDITIONAL OBSERVATIONS:<br />\n",
    "We notice that the number of APREQ flights after APREQ Prescheduling was much higher than the number of APREQ flights before APREQ prescheduling. This is possibly due to seasonal timing (stormy season perhaps?). However, it probably skews our assessment of the differences between the 2 datasets. A more accurate comparison may be done for 2 datasets at the same time of different years.<br />\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONTO THE SECOND QUESTION:<br />  \n",
    "We will assess whether there is a linear relationship between overall delay assigned by TBFM and the flight's distance to the meter fix. First, we will perform a quick test to see if there is potential for a linear relationship by running the linear regression model on normalized data.  If a linear relationship is found, we will perform more rigorous tesing of assumptions as listed here.<br />\n",
    "\n",
    "The assumptions and conditions we will evaluate any time we generate a simple or multiple regression analysis will encompass:<br />\n",
    "â€¢ Linearity<br />\n",
    "â€¢ Homoscedasticity (Constant Variance)<br />\n",
    "â€¢ Normality<br />\n",
    "â€¢ Independence of Error<br />\n",
    "â€¢ Outlier and Influential Observation Analysis<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles for dataset: 25th=5.000, 75th=18.000, IQR=13.000\n",
      "Number of outliers: 154\n",
      "No-outlier observations for dataset: 4279\n",
      "\n",
      "\n",
      "Percentiles for dataset: 25th=136.039, 75th=211.839, IQR=75.800\n",
      "Number of outliers: 56\n",
      "No-outlier observations for dataset: 4377\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "#Remove outliers for data per streamclass  #\n",
    "############################################\n",
    "\n",
    "subset_Delay_ORDDOOGE_noO = pd.DataFrame(outliers_IQR(subset_ORDDOOGE['FinalDelay']))\n",
    "#subset_Delay_ORDDOOGE_noO = subset_ORDDOOGE['FinalDelay'] #if you don't want to remove outliers\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "subset_meterFixDistance_ORDDOOGE_noO = pd.DataFrame(outliers_IQR(subset_ORDDOOGE['meterFixDistance']))\n",
    "#subset_meterFixDistance_ORDDOOGE_noO = subset_ORDDOOGE['meterFixDistance'] #if you don't want to remove outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find best fit pdf for ORDDOOGE delay dataset\n",
      "dweibull  distribution parameters:  (1, 0, 12.080877634438345)\n",
      "SSE for  dweibull :  1.0813190358935625\n",
      "expon  distribution parameters:  (1.0, 11.08087891538102)\n",
      "SSE for  expon :  1.0152343115729416\n",
      "gamma  distribution parameters:  (1.5777643933447205, 0, 7.656960041905007)\n",
      "SSE for  gamma :  1.0234101086367997\n",
      "invweibull  distribution parameters:  (1, 0, 5.358886718750009)\n",
      "SSE for  invweibull :  1.0481759308586276\n",
      "lognorm  distribution parameters:  (0.9161486488590146, 0.0, 8.519850127757808)\n",
      "SSE for  lognorm :  1.0301266905766857\n",
      "norm  distribution parameters:  (12.08087891538102, 9.18377657590736)\n",
      "SSE for  norm :  1.069083296055466\n",
      "weibull_min  distribution parameters:  (1, 0, 12.080859375000024)\n",
      "SSE for  weibull_min :  1.014999147823064\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  1.2448091040099487\n",
      "\n",
      "Find best fit pdf for ORDDOOGE meterFixDistance dataset\n",
      "dweibull  distribution parameters:  (1, 0, 167.81827135066675)\n",
      "SSE for  dweibull :  0.09253773132238313\n",
      "expon  distribution parameters:  (85.46419499999998, 82.3540493235832)\n",
      "SSE for  expon :  0.0905671747722741\n",
      "gamma  distribution parameters:  (13.40707487875979, 0, 12.517140826105914)\n",
      "SSE for  gamma :  0.08908125416967835\n",
      "invweibull  distribution parameters:  (1, 0, 155.41318359375023)\n",
      "SSE for  invweibull :  0.09119583180323103\n",
      "lognorm  distribution parameters:  (0.2775925605454191, 0.0, 161.60004452005663)\n",
      "SSE for  lognorm :  0.08894906617316234\n",
      "norm  distribution parameters:  (167.81824432358317, 45.673925120499874)\n",
      "SSE for  norm :  0.08938443595462807\n",
      "weibull_min  distribution parameters:  (1, 0, 167.81826171875025)\n",
      "SSE for  weibull_min :  0.09119560426687806\n",
      "weibull_max  distribution parameters:  (1, 0, 5.329070518200764e-16)\n",
      "SSE for  weibull_max :  0.09432298869921157\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "#Find best fit pdf for ORDDOOGE delay and meterFixDistance dataset by SSE comparison #\n",
    "#We only use half of the dataset to find the dist params, leave the other half for   #\n",
    "#goodness-of-fit statistical tests                                                   #\n",
    "######################################################################################\n",
    "\n",
    "#Perform evaluation of best fit distribution by\n",
    "#iterating through a list of dist and evaluate fit by computing the sum of squared error\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_PDF_plots.pdf\")\n",
    "\n",
    "X_train_Delay_ORDDOOGE, X_test_Delay_ORDDOOGE = train_test_split(subset_Delay_ORDDOOGE_noO,test_size=.5)\n",
    "X_train_Delay_ORDDOOGE = X_train_Delay_ORDDOOGE.astype(int)\n",
    "X_test_Delay_ORDDOOGE = X_test_Delay_ORDDOOGE.astype(int)\n",
    "\n",
    "X_train_meterFixDistance_ORDDOOGE, X_test_meterFixDistance_ORDDOOGE = train_test_split(subset_meterFixDistance_ORDDOOGE_noO,test_size=.5)\n",
    "X_train_meterFixDistance_ORDDOOGE = X_train_meterFixDistance_ORDDOOGE.astype(float)\n",
    "X_test_meterFixDistance_ORDDOOGE = X_test_meterFixDistance_ORDDOOGE.astype(float)\n",
    "\n",
    "print(\"Find best fit pdf for ORDDOOGE delay dataset\")\n",
    "############################################################\n",
    "# Find best fit pdf for ORDDOOGE delay dataset\n",
    "\n",
    "# use half of dataset (randomly drawn) to find distribution params utilizing fit function\n",
    "#data = subset_Delay_ORDDOOGE_noO\n",
    "data_Delay = X_train_Delay_ORDDOOGE\n",
    "\n",
    "# Plot for comparison\n",
    "plt.figure()\n",
    "ax = data_Delay.plot(kind='hist', bins=50, density=True, alpha=0.5, legend=False)\n",
    "    \n",
    "# Save plot limits\n",
    "dataYLim = ax.get_ylim()\n",
    "\n",
    "# Find best fit distribution\n",
    "best_fit_Delay_name, best_fit_Delay_params = best_fit_distribution(data_Delay, 200, ax)\n",
    "best_Delay_dist = getattr(st, best_fit_Delay_name)\n",
    "\n",
    "# Update plots\n",
    "ax.set_ylim(dataYLim)\n",
    "ax.set_title(u'Delays to ORD_DOOGE\\n Selected Fitted Distributions')\n",
    "ax.set_xlabel('Minutes')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "pdf.savefig()\n",
    "\n",
    "# Make PDF with best params \n",
    "pdf_Delay = make_pdf(best_Delay_dist, best_fit_Delay_params)\n",
    "\n",
    "# Display\n",
    "plt.figure()\n",
    "ax = pdf_Delay.plot(lw=2, label='pdf', legend=True)\n",
    "data_Delay.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=False, ax=ax)\n",
    "\n",
    "param_Delay_names = (best_Delay_dist.shapes + ', loc, scale').split(', ') if best_Delay_dist.shapes else ['loc', 'scale']\n",
    "param_Delay_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_Delay_names, best_fit_Delay_params)])\n",
    "dist_Delay_str = '{}({})'.format(best_fit_Delay_name, param_Delay_str)\n",
    "\n",
    "ax.set_title(u'Delays to ORD_DOOGE with best fit distribution \\n' + dist_Delay_str)\n",
    "ax.set_xlabel('Minutes')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "pdf.savefig()\n",
    "\n",
    "print(\"\\nFind best fit pdf for ORDDOOGE meterFixDistance dataset\")\n",
    "############################################################\n",
    "# Find best fit pdf for ORDDOOGE meterFixDistance dataset\n",
    "\n",
    "# use half of dataset (randomly drawn) to find distribution params utilizing fit function\n",
    "data_mfd = X_train_meterFixDistance_ORDDOOGE\n",
    "\n",
    "# Plot for comparison\n",
    "plt.figure()\n",
    "ax = data_mfd.plot(kind='hist', bins=50, density=True, alpha=0.5, legend=False)\n",
    "\n",
    "# Save plot limits\n",
    "dataYLim = ax.get_ylim()\n",
    "\n",
    "# Find best fit distribution\n",
    "best_fit_mfd_name, best_fit_mfd_params = best_fit_distribution(data_mfd, 200, ax)\n",
    "best_mfd_dist = getattr(st, best_fit_mfd_name)\n",
    "\n",
    "# Update plots\n",
    "ax.set_ylim(dataYLim)\n",
    "ax.set_title(u'Distance to the meter fix - ORD_DOOGE \\n Selected Fitted Distributions')\n",
    "ax.set_xlabel('nm')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "pdf.savefig()\n",
    "\n",
    "# Make PDF with best params \n",
    "pdf_mfd = make_pdf(best_mfd_dist, best_fit_mfd_params)\n",
    "\n",
    "# Display\n",
    "plt.figure()\n",
    "ax = pdf_mfd.plot(lw=2, label='pdf', legend=True)\n",
    "data_mfd.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=False, ax=ax)\n",
    "\n",
    "param_mfd_names = (best_mfd_dist.shapes + ', loc, scale').split(', ') if best_mfd_dist.shapes else ['loc', 'scale']\n",
    "param_mfd_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_mfd_names, best_fit_mfd_params)])\n",
    "dist_mfd_str = '{}({})'.format(best_fit_mfd_name, param_mfd_str)\n",
    "\n",
    "ax.set_title(u'Distance to the meter fix ORD_DOOGE with best fit distribution \\n' + dist_mfd_str)\n",
    "ax.set_xlabel('nm')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "pdf.savefig()\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -2315.645375\n",
      "         Iterations: 62\n",
      "         Function evaluations: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return (a <= x) & (x <= b)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:899: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return (a <= x) & (x <= b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of function evaluations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#Use maximum likelihood estimates (MLE) to find best fit pdf parameters #\n",
    "#########################################################################\n",
    "\n",
    "##########\n",
    "# THIS SECTION NEEDS WORK\n",
    "##########\n",
    "\n",
    "#intro to MLE: https://machinelearningmastery.com/what-is-maximum-likelihood-estimation-in-machine-learning/\n",
    "#also: https://towardsdatascience.com/maximum-likelihood-estimation-explained-normal-distribution-6207b322e47f\n",
    "\n",
    "#The best distribution for your data can be determined by several different ways:\n",
    "#1: the one that gives you the highest log likelihood (aka LL), or lowest negative LL\n",
    "#2: the one that gives you the smallest AIC, BIC or BICc values \n",
    "#(see wiki: http://en.wikipedia.org/wiki/Akaike_information_criterion, \n",
    "# basically can be viewed as log likelihood adjusted for number of parameters, as distribution with more parameters are expected to fit better)\n",
    "#3: the one that maximize the Bayesian posterior probability.\n",
    "#(see wiki: http://en.wikipedia.org/wiki/Posterior_probability)\n",
    "\n",
    "#Of course, if you already have a distribution that should describe your data (based on the theories in your particular field)\n",
    "#and want to stick to that, you will skip the step of identifying the best fit distribution.\n",
    "#scipy does not come with a function to calculate log likelihood (although MLE method is provided), but hard code one is easy, see:\n",
    "#https://stackoverflow.com/questions/18431629/is-the-build-in-probability-density-functions-of-scipy-stat-distributions-slow\n",
    "\n",
    "# use half of dataset (randomly drawn) to find distribution params utilizing MLE\n",
    "x_Delay = X_train_Delay_ORDDOOGE\n",
    "\n",
    "#fit exponential dist\n",
    "best_fit_Delay_params = [1.0, 11.053763440860216] #best fit pdf computed above is diff from expon, set params and use expon anyway\n",
    "params_Delay_exp = best_fit_Delay_params #for this example, take initial params from best fit pdf function call using SSE above\n",
    "params_Delay_exp_SSE = best_fit_Delay_params \n",
    "y_Delay = st.expon.pdf(x_Delay)\n",
    "    \n",
    "#fit gamma dist\n",
    "#params_gamma = scp.stats.gamma.fit(X_train_Delay_ORDDOOGE, floc=0)\n",
    "#y = scp.stats.gamma.pdf(x, params_gamma)\n",
    "\n",
    "#fit lognorm dist\n",
    "#params_lognorm = scp.stats.lognorm.fit(X_train_Delay_ORDDOOGE, floc=0)\n",
    "#y = st.lognorm.pdf(x, params_lognorm)\n",
    "\n",
    "#fit weib dist\n",
    "#params_Delay_weib = st.weibull_min.fit(x_Delay.iloc[:,0], floc=0, f0=1) #have to convert dataframe to series\n",
    "#y = st.weibull_min.pdf(x_Delay, best_fit_Delay_params)\n",
    "\n",
    "# plot y against x\n",
    "#sns.regplot(x_Delay, y_Delay, fit_reg=False)\n",
    "\n",
    "# fit OLS model and summarize\n",
    "#OLS_results = sm.OLS(y,x).fit()\n",
    "#print(OLS_results.summary())\n",
    "#print('OLS Regression Parameters: ', OLS_results.params)\n",
    "\n",
    "# define likelihood function\n",
    "def MLERegression_Delay(params):\n",
    "    # inputs are guesses at our parameters\n",
    "    loc_init, sd = params[0], params[1] #use for expon, halfnorm pdf\n",
    "    \n",
    "    #use for gamma, lognorm, exponnorm (where K is alpha), weibull pdf\n",
    "    #alpha, loc_init, sd = params[0], params[1], params[2] \n",
    "    \n",
    "    #Note that a prediction value is the mean of a distribution\n",
    "    #We often think of a prediction as a single scalar (or vector) value \n",
    "    #that the model predicts will be the output from a given input. \n",
    "    #In fact, the prediction from a regression model is a probability distribution on the values that could be output.\n",
    "    #The single prediction we are used to seeing is just the mean of that distribution.\n",
    "    #See: https://www.cs.cmu.edu/~schneide/tut5/node31.html\n",
    "    yhat = st.expon.pdf(loc_init)\n",
    "    #yhat = scp.stats.gamma.pdf(loc_init, alpha)\n",
    "    #yhat = st.lognorm.pdf(loc_init, alpha)\n",
    "    #yhat = st.weibull_min.pdf(loc_init, alpha)\n",
    "    \n",
    "# next, we flip the Bayesian question\n",
    "# compute PDF of observed values normally distributed around mean (yhat)\n",
    "# with a standard deviation of sd - because central limit theorem.\n",
    "    negLL = -np.sum( st.norm.logpdf(y_Delay, loc=yhat, scale=sd) )\n",
    "# return negative LL\n",
    "    return(negLL)\n",
    "\n",
    "# letâ€™s start with initial coefficients computed above and optimize\n",
    "# to learn more: https://scipy-lectures.org/advanced/mathematical_optimization/\n",
    "results_Delay = minimize(MLERegression_Delay, params_Delay_exp, method='Nelder-Mead', options={'disp': True})\n",
    "MLE_best_fit_Delay_params = results_Delay.x\n",
    "\n",
    "##################################################################\n",
    "# use half of dataset (randomly drawn) to find distribution params utilizing MLE\n",
    "x_mfd = X_train_meterFixDistance_ORDDOOGE\n",
    "\n",
    "#fit exponential dist\n",
    "#params_exp = best_fit_params\n",
    "#y_mfd = st.expon.pdf(x_mfd)\n",
    "\n",
    "#fit gamma dist\n",
    "#params_gamma = scp.stats.gamma.fit(X_train_Delay_ORDDOOGE, floc=0)\n",
    "#y_mfd = scp.stats.gamma.pdf(x_mfd, params_gamma)\n",
    "\n",
    "#fit lognorm dist\n",
    "#params_mfd_lognorm = st.lognorm.fit(X_train_meterFixDistance_ORDDOOGE, floc=0)\n",
    "params_mfd_lognorm = best_fit_mfd_params #for this example, take initial params from best fit pdf function call using SSE above\n",
    "params_mfd_lognorm_SSE = best_fit_mfd_params\n",
    "y_mfd = st.lognorm.pdf(x_mfd, params_mfd_lognorm)\n",
    "\n",
    "#fit halfnorm dist\n",
    "#params_mfd_halfnorm = st.halfnorm.fit(x_mfd)\n",
    "#y_mfd = st.halfnorm.pdf(x_mfd)\n",
    "\n",
    "#fit exponnorm dist\n",
    "#params_mfd_exponnorm = st.exponnorm.fit(x_mfd, floc=0)\n",
    "#y_mfd = st.exponnorm.pdf(pd.DataFrame(x_mfd), best_fit_mfd_params)\n",
    "\n",
    "#fit weib dist\n",
    "#params_weib = st.weibull_min.fit(x.iloc[:,0], floc=0, f0=1) #have to convert dataframe to series\n",
    "#y_mfd = st.weibull_min.pdf(x_mfd, params_weib)\n",
    "\n",
    "# define likelihood function\n",
    "def MLERegression_mfd(params):\n",
    "    # inputs are guesses at our parameters\n",
    "    #loc_init, sd = params[0], params[1] #use for expon, halfnorm pdf\n",
    "    \n",
    "    #use for gamma, lognorm, exponnorm (where K is alpha), weibull pdf\n",
    "    alpha, loc_init, sd = params[0], params[1], params[2]\n",
    "    \n",
    "    #Note that a prediction value is the mean of a distribution\n",
    "    #We often think of a prediction as a single scalar (or vector) value \n",
    "    #that the model predicts will be the output from a given input. \n",
    "    #In fact, the prediction from a regression model is a probability distribution on the values that could be output.\n",
    "    #The single prediction we are used to seeing is just the mean of that distribution.\n",
    "    #See: https://www.cs.cmu.edu/~schneide/tut5/node31.html\n",
    "    #yhat = scp.stats.expon.pdf(loc_init)\n",
    "    #yhat = scp.stats.halfnorm.pdf(loc_init)\n",
    "    #yhat = scp.stats.gamma.pdf(loc_init, alpha)\n",
    "    yhat = st.lognorm.pdf(loc_init, alpha)\n",
    "    #yhat = st.exponnorm.pdf(loc_init, alpha)\n",
    "    #yhat = st.weibull_min.pdf(loc_init, alpha)\n",
    "    \n",
    "# next, we flip the Bayesian question\n",
    "# compute PDF of observed values normally distributed around mean (yhat)\n",
    "# with a standard deviation of sd - because central limit theorem\n",
    "    negLL = -np.sum( st.norm.logpdf(y_mfd, loc=yhat, scale=sd) )\n",
    "# return negative LL\n",
    "    return(negLL)\n",
    "\n",
    "# letâ€™s start with initial coefficients computed above and optimize\n",
    "# to learn more: https://scipy-lectures.org/advanced/mathematical_optimization/\n",
    "results_mfd = minimize(MLERegression_mfd, params_mfd_lognorm, method='Nelder-Mead', options={'disp': True})\n",
    "MLE_best_fit_mfd_params = results_mfd.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test results for Delay dataset using MLE Regression best fit params: D =  1.0 p =  0.0\n",
      "MLE best fit Delay params:  [3.46629421 0.08195949]\n",
      "Compute SSE using MLE best fit Delay params:  5.7882259860622325\n",
      "KS test results for Delay using best fit params w/ SSE compare method: D =  1.0 p =  0.0\n",
      "Best fit Delay params by SSE compare method:  [1.0, 11.053763440860216]\n",
      "Use Lilliefors test results if tested against exp or norm dist:  (0.9561994707795167, 0.0009999999999998899)\n",
      "\n",
      "\n",
      "KS test results for meterFixDistance data using MLE Regression best fit params: D =  1.0 p =  0.0\n",
      "MLE best fit mfd params:  [  0.27759256   0.         161.60004452]\n",
      "Compute SSE using MLE best fit mfd params:  0.09241968854248106\n",
      "KS test results for meterFixDistance data using best fit params w/ SSE compare method: D =  0.9937331698745766 p =  0.0\n",
      "Best fit mfd params by SSE compare method:  (0.2775925605454191, 0.0, 161.60004452005663)\n",
      "Use Lilliefors test results if tested against exp or norm dist:  (0.9996029859471791, 0.0009999999999998899)\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#Run statistical test to assess goodness-of-fit for the ORD_DOOGE delay distribution \n",
    "#The train datatest was used to find distribution parameters.\n",
    "#The KS test is performed on the other half (the test set) of ORDDOOGE delay dataset\n",
    "#You can also use Lilliefors if you test against an exp or norm dist.\n",
    "#The advantage of using Lilliefors is that you test against the whole set of data, instead of having\n",
    "#to split the data into train vs. test set, since Lilliefors will also estimate the params for the distribution\n",
    "#########################################################################\n",
    "\n",
    "#D'sub.05 = 1.36/sqrt(n) where n = 15302/2: D = .016\n",
    "stat_Delay, p_Delay = st.kstest(X_test_Delay_ORDDOOGE, 'expon', args=(MLE_best_fit_Delay_params), alternative='two-sided')\n",
    "print(\"KS test results for Delay dataset using MLE Regression best fit params: D = \", stat_Delay, \"p = \", p_Delay)\n",
    "print (\"MLE best fit Delay params: \", MLE_best_fit_Delay_params)\n",
    "\n",
    "#Compute SSE using MLE best fit Delay params\n",
    "y, x = np.histogram(X_test_Delay_ORDDOOGE, bins=200, density=True)\n",
    "x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "arg = MLE_best_fit_Delay_params[:-2]\n",
    "loc = MLE_best_fit_Delay_params[-2]\n",
    "scale = MLE_best_fit_Delay_params[-1]\n",
    "pdf = st.expon.pdf(x, loc=loc, scale=scale, *arg)\n",
    "sse = np.sum(np.power(y - pdf, 2.0))\n",
    "print(\"Compute SSE using MLE best fit Delay params: \", sse)\n",
    "\n",
    "stat_Delay, p_Delay = st.kstest(X_test_Delay_ORDDOOGE, 'expon', args=(params_Delay_exp_SSE), alternative='two-sided')\n",
    "print(\"KS test results for Delay using best fit params w/ SSE compare method: D = \", stat_Delay, \"p = \", p_Delay)\n",
    "print (\"Best fit Delay params by SSE compare method: \", best_fit_Delay_params)\n",
    "\n",
    "#Run lilliefors test, a Kolmogorov-Smirnov test with estimated parameters, only use for normal and exp dist\n",
    "print(\"Use Lilliefors test results if tested against exp or norm dist: \", lilliefors(subset_Delay_ORDDOOGE_noO, dist='exp', pvalmethod='table'))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "#################################################################\n",
    "#Run KS test on the other half (the test set) of the ORDDOOGE meterFixDistance dataset\n",
    "################################################################\n",
    "\n",
    "#D'sub.05 = 1.36/sqrt(n) where n = 15302/2: D = .016\n",
    "stat_mfd, p_mfd = st.kstest(X_test_meterFixDistance_ORDDOOGE, 'lognorm', args=(MLE_best_fit_mfd_params), alternative='two-sided')\n",
    "print(\"KS test results for meterFixDistance data using MLE Regression best fit params: D = \", stat_Delay, \"p = \", p_Delay)\n",
    "print (\"MLE best fit mfd params: \", MLE_best_fit_mfd_params)\n",
    "\n",
    "#Compute SSE using MLE best fit mfd params\n",
    "y, x = np.histogram(X_test_meterFixDistance_ORDDOOGE, bins=200, density=True)\n",
    "x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "arg = MLE_best_fit_mfd_params[:-2]\n",
    "loc = MLE_best_fit_mfd_params[-2]\n",
    "scale = MLE_best_fit_mfd_params[-1]\n",
    "pdf = st.lognorm.pdf(x, loc=loc, scale=scale, *arg)\n",
    "sse = np.sum(np.power(y - pdf, 2.0))\n",
    "print(\"Compute SSE using MLE best fit mfd params: \", sse)\n",
    "\n",
    "stat_mfd, p_mfd = st.kstest(X_test_meterFixDistance_ORDDOOGE, 'lognorm', args=(params_mfd_lognorm_SSE), alternative='two-sided')\n",
    "print(\"KS test results for meterFixDistance data using best fit params w/ SSE compare method: D = \", stat_mfd, \"p = \", p_mfd)\n",
    "print (\"Best fit mfd params by SSE compare method: \", params_mfd_lognorm_SSE)\n",
    "\n",
    "#Run lilliefors test, a Kolmogorov-Smirnov test with estimated parameters, only use for normal and exp dist\n",
    "print(\"Use Lilliefors test results if tested against exp or norm dist: \", lilliefors(subset_meterFixDistance_ORDDOOGE_noO, dist='norm', pvalmethod='table'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "count  2.139000e+03\n",
      "mean   4.766848e-16\n",
      "std    1.000234e+00\n",
      "min   -1.959802e+00\n",
      "25%   -6.815900e-01\n",
      "50%    6.206125e-02\n",
      "75%    8.098156e-01\n",
      "max    1.901708e+00\n",
      "D'sub.05 for ORD_DOOGE delay data w/ sample size of 2140  =  0.029398963679363954\n",
      "KS test results against normal dist: D =  0.9785301532973321 p =  0.0\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#Normalize Delay data using scaling and power transform #\n",
    "#########################################################\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_PP_Delay_plots.pdf\")\n",
    "\n",
    "X_train_Delay_ORDDOOGE_xformed = xform(X_train_Delay_ORDDOOGE)\n",
    "X_test_Delay_ORDDOOGE_xformed = xform(X_test_Delay_ORDDOOGE)\n",
    "\n",
    "left = -1.8   #x coordinate for text insert\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "prob = st.probplot(X_train_Delay_ORDDOOGE_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "ax.set_title('PP Plot: ORD_DOOGE delays data against a normal dist')\n",
    "top = ax.get_ylim()[1] * 0.75\n",
    "txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "prob = plt.hist(X_train_Delay_ORDDOOGE_xformed)\n",
    "ax.set_title('Histogram of normalized ORD_DOOGE delays data')\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "prob = st.probplot(X_test_Delay_ORDDOOGE_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "ax.set_title('PP Plot: ORD_DOOGE delays data against a normal dist')\n",
    "top = ax.get_ylim()[1] * 0.75\n",
    "txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "prob = plt.hist(X_test_Delay_ORDDOOGE_xformed)\n",
    "ax.set_title('Histogram of normalized ORD_DOOGE delays data')\n",
    "\n",
    "fig.tight_layout()\n",
    "pdf.savefig()\n",
    "\n",
    "#Run KS test against a normal dist on test dataset using params derived from train dataset\n",
    "s = pd.DataFrame(X_train_Delay_ORDDOOGE_xformed).describe(include='all')\n",
    "print (s)\n",
    "X_train_Delay_ORDDOOGE_fit_params = [s.loc['mean'], s.loc['std']]\n",
    "statTest, pTest = st.kstest(X_test_Delay_ORDDOOGE_xformed, 'norm', args=(X_train_Delay_ORDDOOGE_fit_params))\n",
    "sizeX_test = len(X_test_Delay_ORDDOOGE_xformed)\n",
    "print (\"D'sub.05 for ORD_DOOGE delay data w/ sample size of\", sizeX_test, \" = \", 1.36/np.sqrt(sizeX_test))\n",
    "print(\"KS test results against normal dist: D = \", statTest, \"p = \", pTest)\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "count  2.188000e+03\n",
      "mean  -1.280308e-15\n",
      "std    1.000229e+00\n",
      "min   -2.146821e+00\n",
      "25%   -6.476874e-01\n",
      "50%   -4.074602e-01\n",
      "75%    9.777444e-01\n",
      "max    2.573327e+00\n",
      "D'sub.05 for distance to the meter fix ORD_DOOGE data w/ sample size of 2189  =  0.029068058636443742\n",
      "KS test results against normal dist: D =  0.9960206175150087 p =  0.0\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#normalize meterFixDistance data using scaling and power transform #\n",
    "####################################################################\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_PP_mfd_plots.pdf\")\n",
    "\n",
    "X_train_meterFixDistance_ORDDOOGE_xformed = xform(X_train_meterFixDistance_ORDDOOGE)\n",
    "X_test_meterFixDistance_ORDDOOGE_xformed = xform(X_test_meterFixDistance_ORDDOOGE)\n",
    "\n",
    "left = -1.8   #x coordinate for text insert\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "prob = st.probplot(X_train_meterFixDistance_ORDDOOGE_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "ax.set_title('PP Plot: distance to the meter fix ORD_DOOGE data against a normal dist')\n",
    "top = ax.get_ylim()[1] * 0.75\n",
    "txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "prob = plt.hist(X_train_meterFixDistance_ORDDOOGE_xformed)\n",
    "ax.set_title('Histogram of normalized distance to the meter fix ORD_DOOGE data')\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "prob = st.probplot(X_test_meterFixDistance_ORDDOOGE_xformed.flatten(), dist=st.norm, plot=ax)\n",
    "ax.set_title('PP Plot: distance to the meter fix ORD_DOOGE data against a normal dist')\n",
    "top = ax.get_ylim()[1] * 0.75\n",
    "txt = ax.text(left, top, 'Data is normalized using Box-Cox transformation', verticalalignment='top')\n",
    "txt.set_bbox(dict(facecolor='k', alpha=0.1))\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "prob = plt.hist(X_test_meterFixDistance_ORDDOOGE_xformed)\n",
    "ax.set_title('Histogram of normalized distance to the meter fix ORD_DOOGE data')\n",
    "fig.tight_layout()\n",
    "\n",
    "pdf.savefig()\n",
    "\n",
    "#Run KS test against a normal dist on test dataset using params derived from train dataset\n",
    "s = pd.DataFrame(X_train_meterFixDistance_ORDDOOGE_xformed).describe(include='all')\n",
    "print (s)\n",
    "X_train_meterFixDistance_ORDDOOGE_fit_params = [s.loc['mean'], s.loc['std']]\n",
    "statTest_mfd, pTest_mfd = st.kstest(X_test_meterFixDistance_ORDDOOGE_xformed, 'norm', args=(X_train_meterFixDistance_ORDDOOGE_fit_params))\n",
    "sizeX_mfd_test = len(X_test_meterFixDistance_ORDDOOGE_xformed)\n",
    "print (\"D'sub.05 for distance to the meter fix ORD_DOOGE data w/ sample size of\", sizeX_mfd_test, \" = \", 1.36/np.sqrt(sizeX_mfd_test))\n",
    "print(\"KS test results against normal dist: D = \", statTest_mfd, \"p = \", pTest_mfd)\n",
    "\n",
    "plt.close('all')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initial size:  4433\n",
      "Percentiles for dataset: 25th=5.000, 75th=18.000, IQR=13.000\n",
      "Non-outlier observations for ORD_DOOGE delay: 4279\n",
      "Percentiles for dataset: 25th=136.039, 75th=211.839, IQR=75.800\n",
      "Non-outlier observations for meterFixDistance: 4377\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "#format & transform data for linear regression #\n",
    "################################################\n",
    "\n",
    "\n",
    "#To retain the integrity of [distance, delay] pairs, first we create tuples\n",
    "subsetReg_ORDDOOGE = []\n",
    "for x,y in zip(subset_ORDDOOGE['meterFixDistance'], subset_ORDDOOGE['FinalDelay']):\n",
    "    subsetReg_ORDDOOGE.append([x,y])\n",
    "print(\"Dataset initial size: \", len(subsetReg_ORDDOOGE))\n",
    "\n",
    "\n",
    "# remove outliers for delays or y using IQR\n",
    "# calculate interquartile range\n",
    "q25_delay, q75_delay = np.percentile(subset_ORDDOOGE['FinalDelay'], 25), np.percentile(subset_ORDDOOGE['FinalDelay'], 75)\n",
    "iqr_delay = q75_delay - q25_delay\n",
    "print('Percentiles for dataset: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25_delay, q75_delay, iqr_delay))\n",
    "# calculate the outlier cutoff\n",
    "cut_off_delay = iqr_delay * 1.5\n",
    "lower_delay, upper_delay = q25_delay - cut_off_delay, q75_delay + cut_off_delay\n",
    "\n",
    "subsetReg_ORDDOOGE_noO = [pair for pair in subsetReg_ORDDOOGE if pair[1] >= lower_delay and pair[1] <= upper_delay]\n",
    "print('Non-outlier observations for ORD_DOOGE delay: %d' % len(subsetReg_ORDDOOGE_noO))\n",
    "\n",
    "\n",
    "# remove outliers for mfd or x using IQR\n",
    "# calculate interquartile range\n",
    "q25_mfd, q75_mfd = np.percentile(subset_ORDDOOGE['meterFixDistance'], 25), np.percentile(subset_ORDDOOGE['meterFixDistance'], 75)\n",
    "iqr_mfd = q75_mfd - q25_mfd\n",
    "print('Percentiles for dataset: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25_mfd, q75_mfd, iqr_mfd))\n",
    "# calculate the outlier cutoff\n",
    "cut_off_mfd = iqr_mfd * 1.5\n",
    "lower_mfd, upper_mfd = q25_mfd - cut_off_mfd, q75_mfd + cut_off_mfd\n",
    "\n",
    "subsetReg_ORDDOOGE_noO = [pair for pair in subsetReg_ORDDOOGE if pair[0] >= lower_mfd and pair[0] <= upper_mfd]\n",
    "print('Non-outlier observations for meterFixDistance: %d' % len(subsetReg_ORDDOOGE_noO))\n",
    "\n",
    "\n",
    "#Then transform the tuple into a list to perform normalization\n",
    "subsetReg_ORDDOOGE = []\n",
    "subsetReg_woO_ORDDOOGE = [[pair[0] for pair in subsetReg_ORDDOOGE_noO], [pair[1] for pair in subsetReg_ORDDOOGE_noO]]\n",
    "\n",
    "#normalize meterFixDistance data using scaling\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "subsetReg_ORDDOOGE_normalized = [max_abs_scaler.fit_transform(pd.DataFrame(subsetReg_woO_ORDDOOGE[0])), subsetReg_woO_ORDDOOGE[1]]\n",
    "\n",
    "#Normalize Delay data using scaling & Yeo-Johnson\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "subsetReg_ORDDOOGE_normalized = [subsetReg_ORDDOOGE_normalized[0], mm_scaler.fit_transform(pd.DataFrame(subsetReg_woO_ORDDOOGE[1]))]\n",
    "\n",
    "X_Reg_ORDDOOGE = preprocessing.power_transform(subsetReg_ORDDOOGE_normalized[0], method='yeo-johnson')\n",
    "Y_Reg_ORDDOOGE = preprocessing.power_transform(subsetReg_ORDDOOGE_normalized[1], method='yeo-johnson')\n",
    "\n",
    "#If you want to use box-cox transformation, you need to transform the list to tuples again to retain\n",
    "#only positive data, or skip the scaler (see the xform function call)\n",
    "#subsetReg_ORDDOOGE = []\n",
    "#for x,y in zip(subsetReg_ORDDOOGE_normalized[0], subsetReg_ORDDOOGE_normalized[1]):\n",
    "#    subsetReg_ORDDOOGE.append([x,y])\n",
    "\n",
    "#Keep stricly positive data only\n",
    "#subsetReg_ORDDOOGE_keep_pos = [pair for pair in subsetReg_ORDDOOGE if pair[0] > 0 and pair[1] > 0]\n",
    "\n",
    "#Transform the tuples into a list\n",
    "#subsetReg_ORDDOOGE = []\n",
    "#subsetReg_ORDDOOGE = [[float(pair[0]) for pair in subsetReg_ORDDOOGE_keep_pos], [float(pair[1]) for pair in subsetReg_ORDDOOGE_keep_pos]]\n",
    "\n",
    "#Run boxcox power transform\n",
    "#X_Reg_ORDDOOGE = st.boxcox(subsetReg_ORDDOOGE[0], 1)\n",
    "#Y_Reg_ORDDOOGE = st.boxcox(subsetReg_ORDDOOGE[1], 0)\n",
    "\n",
    "#df = pd.DataFrame({'mfd': X_Reg_ORDDOOGE, 'delay': Y_Reg_ORDDOOGE})\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit linear regression model on normalized dataset\n",
      "intercept:  [-0.00159799]\n",
      "slope:  [[-0.08499588]]\n",
      "Statistics for ORD_DOOGE delays - normalized test set\n",
      "MSE: 0.986\n",
      "RMSE: 0.993\n",
      "AIC: -26.181\n",
      "BIC: -14.798\n",
      "Pearson Coefficient for ORD_DOOGE delays -  normalized test set:\n",
      " (-0.09136353074898425, 1.8595736336258186e-05)\n",
      "LinregressResult(slope=-0.09040896350383074, intercept=0.0015482686919906148, rvalue=-0.09136353074898423, pvalue=1.8595736336204037e-05, stderr=0.021071430725717863)\n",
      "\n",
      "Fit linear regression model on raw dataset, outliers removed\n",
      "However, note that linear regression works best on normalized data\n",
      "intercept:  [17.83999279]\n",
      "slope:  [[-0.02853896]]\n",
      "Statistics for ORD_DOOGE delays - raw test set\n",
      "MSE: 114.789\n",
      "RMSE: 10.714\n",
      "AIC: 10386.627\n",
      "BIC: 10398.009\n",
      "Note that the Pearson Coefficient works strictly on normalized data.\n",
      "However, here's the Pearson Coefficient for ORD_DOOGE delays on raw test set:\n",
      " (-0.0846093955132574, 7.38755720853427e-05)\n",
      "LinregressResult(slope=-0.019734377663669374, intercept=16.513937277636586, rvalue=-0.08460939551325737, pvalue=7.387557208509617e-05, stderr=0.0049695876844125745)\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "#Fit linear regression model to transformed data #\n",
    "#Compute Pearson coefficient                     #\n",
    "##################################################\n",
    "\n",
    "#########################################\n",
    "# Linear regression on normalized data\n",
    "\n",
    "print('Fit linear regression model on normalized dataset')\n",
    "X_train_Reg_ORDDOOGE, X_test_Reg_ORDDOOGE, Y_train_Reg_ORDDOOGE, Y_test_Reg_ORDDOOGE = train_test_split(X_Reg_ORDDOOGE.flatten(), Y_Reg_ORDDOOGE.flatten(), test_size=.5)\n",
    "\n",
    "# define and fit the model on all data\n",
    "model = LinearRegression()\n",
    "model.fit(pd.DataFrame(X_train_Reg_ORDDOOGE), pd.DataFrame(Y_train_Reg_ORDDOOGE))\n",
    "\n",
    "#To retrieve the intercept:\n",
    "print(\"intercept: \", model.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(\"slope: \", model.coef_)\n",
    "\n",
    "# number of parameters\n",
    "num_params = len(model.coef_) + 1\n",
    "#print('Number of parameters: %d' % (num_params))\n",
    "\n",
    "# predict the training set\n",
    "yhat = model.predict(pd.DataFrame(X_test_Reg_ORDDOOGE))\n",
    "\n",
    "#df = pd.DataFrame({'Actual': Y_test_Reg_ORDDOOGE.to_numpy().flatten(), 'Predicted': yhat.flatten()})\n",
    "#print(df)\n",
    "print('Statistics for ORD_DOOGE delays - normalized test set')\n",
    "#print(pd.DataFrame(Y_test_Reg_ORDDOOGE).describe())\n",
    "\n",
    "# calculate the error\n",
    "mse = mean_squared_error(Y_test_Reg_ORDDOOGE, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "# calculate the aic\n",
    "aic = calculate_aic(len(Y_test_Reg_ORDDOOGE), mse, num_params)\n",
    "print('AIC: %.3f' % aic)\n",
    "# calculate the bic\n",
    "bic = calculate_bic(len(Y_test_Reg_ORDDOOGE), mse, num_params)\n",
    "print('BIC: %.3f' % bic)\n",
    "\n",
    "#compute the pearson coefficient\n",
    "#to learn more: https://machinelearningmastery.com/how-to-use-correlation-to-understand-the-relationship-between-variables/\n",
    "print(\"Pearson Coefficient for ORD_DOOGE delays -  normalized test set:\\n\", st.pearsonr(X_test_Reg_ORDDOOGE, Y_test_Reg_ORDDOOGE))\n",
    "print(st.linregress(X_test_Reg_ORDDOOGE, Y_test_Reg_ORDDOOGE))\n",
    "\n",
    "##################################################\n",
    "# Linear regression on raw data, outliers removed\n",
    "\n",
    "print('\\nFit linear regression model on raw dataset, outliers removed')\n",
    "print('However, note that linear regression works best on normalized data')\n",
    "X_train_Reg_ORDDOOGE_raw, X_test_Reg_ORDDOOGE_raw, Y_train_Reg_ORDDOOGE_raw, Y_test_Reg_ORDDOOGE_raw = train_test_split(subsetReg_woO_ORDDOOGE[0], subsetReg_woO_ORDDOOGE[1], test_size=.5)\n",
    "\n",
    "model.fit(pd.DataFrame(X_train_Reg_ORDDOOGE_raw), pd.DataFrame(Y_train_Reg_ORDDOOGE_raw))\n",
    "\n",
    "#To retrieve the intercept:\n",
    "print(\"intercept: \", model.intercept_)\n",
    "#For retrieving the slope:\n",
    "print(\"slope: \", model.coef_)\n",
    "\n",
    "# number of parameters\n",
    "num_params_raw = len(model.coef_) + 1\n",
    "#print('Number of parameters: %d' % (num_params))\n",
    "\n",
    "# predict the training set\n",
    "yhat_raw = model.predict(pd.DataFrame(X_test_Reg_ORDDOOGE_raw))\n",
    "\n",
    "#df = pd.DataFrame({'Actual': Y_test_Reg_ORDDOOGE.to_numpy().flatten(), 'Predicted': yhat.flatten()})\n",
    "#print(df)\n",
    "\n",
    "print('Statistics for ORD_DOOGE delays - raw test set')\n",
    "#print(pd.DataFrame(Y_test_Reg_ORDDOOGE_raw).describe())\n",
    "\n",
    "# calculate the error\n",
    "mse_raw = mean_squared_error(Y_test_Reg_ORDDOOGE_raw, yhat_raw)\n",
    "print('MSE: %.3f' % mse_raw)\n",
    "rmse_raw = np.sqrt(mse_raw)\n",
    "print('RMSE: %.3f' % rmse_raw)\n",
    "# calculate the aic\n",
    "aic_raw = calculate_aic(len(Y_test_Reg_ORDDOOGE_raw), mse_raw, num_params_raw)\n",
    "print('AIC: %.3f' % aic_raw)\n",
    "# calculate the bic\n",
    "bic_raw = calculate_bic(len(Y_test_Reg_ORDDOOGE_raw), mse_raw, num_params_raw)\n",
    "print('BIC: %.3f' % bic_raw)\n",
    "\n",
    "#Pearson coefficient\n",
    "print(\"Note that the Pearson Coefficient works strictly on normalized data.\")\n",
    "print(\"However, here's the Pearson Coefficient for ORD_DOOGE delays on raw test set:\\n\", st.pearsonr(X_test_Reg_ORDDOOGE_raw, Y_test_Reg_ORDDOOGE_raw))\n",
    "print(st.linregress(X_test_Reg_ORDDOOGE_raw, Y_test_Reg_ORDDOOGE_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#Scatter plot for raw data w/o outliers          #\n",
    "##################################################\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_scatterPlots_noOutliers.pdf\")\n",
    "\n",
    "\n",
    "Reg_ORDDOOGE_raw=pd.DataFrame(list(zip(subsetReg_woO_ORDDOOGE[0], subsetReg_woO_ORDDOOGE[1])),\n",
    "                            columns=['meterFixDistance', 'Delay'])\n",
    "\n",
    "ax1 = sns.scatterplot(Reg_ORDDOOGE_raw['meterFixDistance'], Reg_ORDDOOGE_raw['Delay'], palette='GnBu_r',\n",
    "                  hue=Reg_ORDDOOGE_raw['Delay'], size=Reg_ORDDOOGE_raw['meterFixDistance'], linewidth=1, alpha = 1)\n",
    "\n",
    "ax1.set_title('Scatter plot for ORD_DOOGE - raw data w/o outliers')\n",
    "ax1.set_xlabel('Meter Fix Distance (nm)')\n",
    "ax1.set_ylabel('Delay (minutes)')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "pdf.savefig()\n",
    "plt.close('all')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#Scatter plot for normalized data                #\n",
    "##################################################\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"ORDDOOGE_scatterPlots_normalized.pdf\")\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "\n",
    "Reg_ORDDOOGE=pd.DataFrame(list(zip(X_Reg_ORDDOOGE.flatten(), Y_Reg_ORDDOOGE.flatten())),\n",
    "                            columns=['meterFixDistance', 'Delay'])\n",
    "\n",
    "ax1 = sns.scatterplot(Reg_ORDDOOGE['meterFixDistance'], Reg_ORDDOOGE['Delay'], palette='GnBu_r',\n",
    "                  hue=Reg_ORDDOOGE['Delay'], size=Reg_ORDDOOGE['meterFixDistance'], linewidth=1, alpha = 1)\n",
    "\n",
    "ax1.set_title('Scatter plot for ORD_DOOGE - normalized data')\n",
    "ax1.set_xlabel('Meter Fix Distance (nm)')\n",
    "ax1.set_ylabel('Delay (minutes)')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "pdf.savefig()\n",
    "plt.close('all')\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOME REMARKS FOR THE SECOND QUESTION:<br />\n",
    "Here, eventhough we did not pass normality tests for both delay and meterFixDistance, we went ahead and perform a linear regression anyway. We did not find a linear relationship between these 2 datasets. At this point, we should assess for additional features that could correlate with the delay. For example:<br />\n",
    "- time of day/week/year<br />\n",
    "- <br />  \n",
    "\n",
    "We can statistically assess 2-3 features for correlation with our target variable.  Using ANOVA, we can assess the features at several different levels for each feature. We can also perform multiple regression.  Statistical methodologies beyond 3 features start to become more and more burdensome however, and here is where we hope machine-learning techniques can pick up the baton.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
